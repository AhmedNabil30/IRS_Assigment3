{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_path = r\"C:\\Users\\Hamed\\asgmnt 1 (IRS)\\dataset\\movies.dat\"\n",
    "ratings_path = r\"C:\\Users\\Hamed\\asgmnt 1 (IRS)\\dataset\\ratings.dat\"\n",
    "users_path = r\"C:\\Users\\Hamed\\asgmnt 1 (IRS)\\dataset\\users.dat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv(\n",
    "    movies_path, \n",
    "    delimiter='::', \n",
    "    engine='python', \n",
    "    encoding='ISO-8859-1', \n",
    "    names=['MovieID', 'Title', 'Genres']\n",
    ")\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    ratings_path, \n",
    "    delimiter='::', \n",
    "    engine='python', \n",
    "    encoding='ISO-8859-1', \n",
    "    names=['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    ")\n",
    "\n",
    "users = pd.read_csv(\n",
    "    users_path, \n",
    "    delimiter='::', \n",
    "    engine='python', \n",
    "    encoding='ISO-8859-1', \n",
    "    names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_csv(r\"C:\\Users\\Hamed\\asgmnt 1 (IRS)\\dataset\\movies.csv\", index=False)\n",
    "ratings.to_csv(r\"C:\\Users\\Hamed\\asgmnt 1 (IRS)\\dataset\\ratings.csv\", index=False)\n",
    "users.to_csv(r\"C:\\Users\\Hamed\\asgmnt 1 (IRS)\\dataset\\users.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 part 1 (PCA Method with Mean-Filling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1: Calculate the average rating for each of the target items (I1 and I2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating for I1 (MovieID: 127): 1.0\n",
      "Average rating for I2 (MovieID: 133): 1.0\n"
     ]
    }
   ],
   "source": [
    "item_avg_ratings = ratings.groupby('MovieID')['Rating'].mean()\n",
    "I1, I2 = item_avg_ratings.nsmallest(2).index\n",
    "I1_avg_rating = item_avg_ratings.loc[I1]\n",
    "I2_avg_rating = item_avg_ratings.loc[I2]\n",
    "print(f\"Average rating for I1 (MovieID: {I1}): {I1_avg_rating}\")\n",
    "print(f\"Average rating for I2 (MovieID: {I2}): {I2_avg_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2: Use the mean-filling method to replace the unspecified ratings of each of the target items (I1 and I2) with its corresponding mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n"
     ]
    }
   ],
   "source": [
    "ratings_filled = ratings.copy()\n",
    "\n",
    "ratings_filled.loc[ratings_filled['MovieID'] == I1, 'Rating'] = ratings_filled.loc[ratings_filled['MovieID'] == I1, 'Rating'].fillna(I1_avg_rating)\n",
    "ratings_filled.loc[ratings_filled['MovieID'] == I2, 'Rating'] = ratings_filled.loc[ratings_filled['MovieID'] == I2, 'Rating'].fillna(I2_avg_rating)\n",
    "print(ratings_filled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.3: Calculate the average rating for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieID\n",
      "1    4.146846\n",
      "2    3.201141\n",
      "3    3.016736\n",
      "4    2.729412\n",
      "5    3.006757\n",
      "Name: Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "item_avg_ratings_filled = ratings_filled.groupby('MovieID')['Rating'].mean()\n",
    "\n",
    "print(item_avg_ratings_filled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.4: For each item, calculate the difference between ratings and the mean rating of the item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  MovieID  Rating  Rating_Diff\n",
      "0       1     1193       5     0.609275\n",
      "1       1      661       3    -0.464762\n",
      "2       1      914       3    -1.154088\n",
      "3       1     3408       4     0.136122\n",
      "4       1     2355       5     1.145625\n"
     ]
    }
   ],
   "source": [
    "ratings_filled['Rating_Diff'] = ratings_filled['Rating'] - ratings_filled['MovieID'].map(item_avg_ratings_filled)\n",
    "\n",
    "print(ratings_filled[['UserID', 'MovieID', 'Rating', 'Rating_Diff']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.5: Compute the covariance for each pair of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieID      1         2         3         4         5         6         7     \\\n",
      "MovieID                                                                         \n",
      "1        0.726499  0.154599  0.145391  0.334540  0.139716  0.041210  0.117566   \n",
      "2        0.154599  0.966627  0.142157  0.062013  0.335331  0.068046  0.221806   \n",
      "3        0.145391  0.142157  1.148566  0.278689  0.451023  0.176220  0.225447   \n",
      "4        0.334540  0.062013  0.278689  1.026940  0.440977 -0.011202  0.075448   \n",
      "5        0.139716  0.335331  0.451023  0.440977  1.050802  0.073866  0.253444   \n",
      "\n",
      "MovieID      8         9         10    ...      3943      3944      3945  \\\n",
      "MovieID                                ...                                 \n",
      "1        0.138824 -0.035088  0.108824  ... -0.099915  0.083333  0.154839   \n",
      "2        0.266888  0.401786  0.224986  ...  0.010526 -0.500000  0.187500   \n",
      "3        0.327485  0.173950  0.252696  ... -0.133333  0.333333 -0.266667   \n",
      "4        0.071429 -0.660256  0.009351  ...  0.785714       NaN       NaN   \n",
      "5        0.571429  0.498851  0.192163  ... -0.600000  0.333333  0.000000   \n",
      "\n",
      "MovieID      3946      3947      3948      3949      3950          3951  \\\n",
      "MovieID                                                                   \n",
      "1        0.103594  0.517544  0.117767  0.152621  0.150568  2.500000e-01   \n",
      "2        0.136752  0.050000  0.213012  0.074787 -0.073529 -2.500000e-01   \n",
      "3        0.215415 -0.032967  0.307597  0.024490  0.424242  0.000000e+00   \n",
      "4        0.133333 -0.333333  0.234398 -0.427350  0.333333  1.110223e-16   \n",
      "5        0.458333  2.000000  0.396450 -0.120968  0.309524  0.000000e+00   \n",
      "\n",
      "MovieID      3952  \n",
      "MovieID            \n",
      "1        0.119849  \n",
      "2        0.069014  \n",
      "3        0.107755  \n",
      "4        0.112536  \n",
      "5       -0.025000  \n",
      "\n",
      "[5 rows x 3706 columns]\n"
     ]
    }
   ],
   "source": [
    "ratings_matrix = ratings_filled.pivot(index='UserID', columns='MovieID', values='Rating')\n",
    "covariance_matrix = ratings_matrix.cov()\n",
    "print(covariance_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.6: Generate the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieID      1         2         3         4         5         6         7     \\\n",
      "MovieID                                                                         \n",
      "1        0.726499  0.154599  0.145391  0.334540  0.139716  0.041210  0.117566   \n",
      "2        0.154599  0.966627  0.142157  0.062013  0.335331  0.068046  0.221806   \n",
      "3        0.145391  0.142157  1.148566  0.278689  0.451023  0.176220  0.225447   \n",
      "4        0.334540  0.062013  0.278689  1.026940  0.440977 -0.011202  0.075448   \n",
      "5        0.139716  0.335331  0.451023  0.440977  1.050802  0.073866  0.253444   \n",
      "\n",
      "MovieID      8         9         10    ...      3943      3944      3945  \\\n",
      "MovieID                                ...                                 \n",
      "1        0.138824 -0.035088  0.108824  ... -0.099915  0.083333  0.154839   \n",
      "2        0.266888  0.401786  0.224986  ...  0.010526 -0.500000  0.187500   \n",
      "3        0.327485  0.173950  0.252696  ... -0.133333  0.333333 -0.266667   \n",
      "4        0.071429 -0.660256  0.009351  ...  0.785714       NaN       NaN   \n",
      "5        0.571429  0.498851  0.192163  ... -0.600000  0.333333  0.000000   \n",
      "\n",
      "MovieID      3946      3947      3948      3949      3950          3951  \\\n",
      "MovieID                                                                   \n",
      "1        0.103594  0.517544  0.117767  0.152621  0.150568  2.500000e-01   \n",
      "2        0.136752  0.050000  0.213012  0.074787 -0.073529 -2.500000e-01   \n",
      "3        0.215415 -0.032967  0.307597  0.024490  0.424242  0.000000e+00   \n",
      "4        0.133333 -0.333333  0.234398 -0.427350  0.333333  1.110223e-16   \n",
      "5        0.458333  2.000000  0.396450 -0.120968  0.309524  0.000000e+00   \n",
      "\n",
      "MovieID      3952  \n",
      "MovieID            \n",
      "1        0.119849  \n",
      "2        0.069014  \n",
      "3        0.107755  \n",
      "4        0.112536  \n",
      "5       -0.025000  \n",
      "\n",
      "[5 rows x 3706 columns]\n"
     ]
    }
   ],
   "source": [
    "covariance_matrix = ratings_matrix.cov()\n",
    "\n",
    "print(covariance_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.7: Determine the top 5-peers and top 10-peers for each of the target items (I1 and I2) using the transformed representation (covariance matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 peers for I1 (MovieID: 127): MovieID\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "5   NaN\n",
      "6   NaN\n",
      "Name: 127, dtype: float64\n",
      "Top 5 peers for I2 (MovieID: 133): MovieID\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "5   NaN\n",
      "6   NaN\n",
      "Name: 133, dtype: float64\n",
      "Top 10 peers for I1 (MovieID: 127): MovieID\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8    NaN\n",
      "9    NaN\n",
      "10   NaN\n",
      "11   NaN\n",
      "Name: 127, dtype: float64\n",
      "Top 10 peers for I2 (MovieID: 133): MovieID\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8    NaN\n",
      "9    NaN\n",
      "10   NaN\n",
      "11   NaN\n",
      "Name: 133, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_5_peers_I1 = covariance_matrix[I1].sort_values(ascending=False).iloc[1:6]  \n",
    "top_5_peers_I2 = covariance_matrix[I2].sort_values(ascending=False).iloc[1:6] \n",
    "\n",
    "top_10_peers_I1 = covariance_matrix[I1].sort_values(ascending=False).iloc[1:11] \n",
    "top_10_peers_I2 = covariance_matrix[I2].sort_values(ascending=False).iloc[1:11]  \n",
    "\n",
    "print(f\"Top 5 peers for I1 (MovieID: {I1}): {top_5_peers_I1}\")\n",
    "print(f\"Top 5 peers for I2 (MovieID: {I2}): {top_5_peers_I2}\")\n",
    "print(f\"Top 10 peers for I1 (MovieID: {I1}): {top_10_peers_I1}\")\n",
    "print(f\"Top 10 peers for I2 (MovieID: {I2}): {top_10_peers_I2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.8: Determine reduced dimensional space for each user in case of using the top 5-peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dimensional space (Top 5 peers):\n",
      "[[-0.70905081 -0.27783914]\n",
      " [-0.70905081 -0.27783914]\n",
      " [-0.70905081 -0.27783914]\n",
      " [-0.70905081 -0.27783914]\n",
      " [ 1.21437332 -0.82227991]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "top_5_peers_I1_and_I2 = list(set(top_5_peers_I1.index) | set(top_5_peers_I2.index))  \n",
    "ratings_reduced_5 = ratings_matrix[top_5_peers_I1_and_I2].fillna(0)\n",
    "\n",
    "pca_5 = PCA(n_components=2)\n",
    "ratings_reduced_5_pca = pca_5.fit_transform(ratings_reduced_5)\n",
    "\n",
    "print(\"Reduced dimensional space (Top 5 peers):\")\n",
    "print(ratings_reduced_5_pca[:5])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.9: Compute the rating predictions of the original missing rating for each of the target items (I1 and I2) using the top 5-peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for I1 (using top 5 peers): UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n",
      "Predicted rating for I2 (using top 5 peers): UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predicted_rating_I1_5 = ratings_reduced_5[top_5_peers_I1.index].mean(axis=1)\n",
    "predicted_rating_I2_5 = ratings_reduced_5[top_5_peers_I2.index].mean(axis=1)\n",
    "\n",
    "print(f\"Predicted rating for I1 (using top 5 peers): {predicted_rating_I1_5[:5]}\")\n",
    "print(f\"Predicted rating for I2 (using top 5 peers): {predicted_rating_I2_5[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.10: Determine reduced dimensional space for each user in case of using the top 10-peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dimensional space (Top 10 peers):\n",
      "[[-1.15850786  0.00702471]\n",
      " [-1.15850786  0.00702471]\n",
      " [-1.15850786  0.00702471]\n",
      " [-1.15850786  0.00702471]\n",
      " [-0.12305775 -1.27991222]]\n"
     ]
    }
   ],
   "source": [
    "top_10_peers_I1_and_I2 = list(set(top_10_peers_I1.index) | set(top_10_peers_I2.index))  \n",
    "ratings_reduced_10 = ratings_matrix[top_10_peers_I1_and_I2].fillna(0)\n",
    "\n",
    "\n",
    "pca_10 = PCA(n_components=2) \n",
    "ratings_reduced_10_pca = pca_10.fit_transform(ratings_reduced_10)\n",
    "\n",
    "print(\"Reduced dimensional space (Top 10 peers):\")\n",
    "print(ratings_reduced_10_pca[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.11: Compute the rating predictions of the original missing rating for each of the target items (I1 and I2) using the top 10-peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for I1 (using top 10 peers): UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n",
      "Predicted rating for I2 (using top 10 peers): UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predicted_rating_I1_10 = ratings_reduced_10[top_10_peers_I1.index].mean(axis=1)\n",
    "predicted_rating_I2_10 = ratings_reduced_10[top_10_peers_I2.index].mean(axis=1)\n",
    "\n",
    "print(f\"Predicted rating for I1 (using top 10 peers): {predicted_rating_I1_10[:5]}\")\n",
    "print(f\"Predicted rating for I2 (using top 10 peers): {predicted_rating_I2_10[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.12: Compare the results of point 3.2.9 with results of point 3.2.11. Comment on your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of predicted ratings for I1:\n",
      "Top 5: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n",
      "Top 10: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n",
      "Comparison of predicted ratings for I2:\n",
      "Top 5: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n",
      "Top 10: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Comparison of predicted ratings for I1:\\nTop 5: {predicted_rating_I1_5[:5]}\\nTop 10: {predicted_rating_I1_10[:5]}\")\n",
    "print(f\"Comparison of predicted ratings for I2:\\nTop 5: {predicted_rating_I2_5[:5]}\\nTop 10: {predicted_rating_I2_10[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2: PCA Method with Maximum Likelihood Estimation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.1: Generate the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix (MLE):\n",
      "MovieID      1         2         3         4         5         6         7     \\\n",
      "MovieID                                                                         \n",
      "1        0.726499  0.154599  0.145391  0.334540  0.139716  0.041210  0.117566   \n",
      "2        0.154599  0.966627  0.142157  0.062013  0.335331  0.068046  0.221806   \n",
      "3        0.145391  0.142157  1.148566  0.278689  0.451023  0.176220  0.225447   \n",
      "4        0.334540  0.062013  0.278689  1.026940  0.440977 -0.011202  0.075448   \n",
      "5        0.139716  0.335331  0.451023  0.440977  1.050802  0.073866  0.253444   \n",
      "\n",
      "MovieID      8         9         10    ...      3943      3944      3945  \\\n",
      "MovieID                                ...                                 \n",
      "1        0.138824 -0.035088  0.108824  ... -0.099915  0.083333  0.154839   \n",
      "2        0.266888  0.401786  0.224986  ...  0.010526 -0.500000  0.187500   \n",
      "3        0.327485  0.173950  0.252696  ... -0.133333  0.333333 -0.266667   \n",
      "4        0.071429 -0.660256  0.009351  ...  0.785714       NaN       NaN   \n",
      "5        0.571429  0.498851  0.192163  ... -0.600000  0.333333  0.000000   \n",
      "\n",
      "MovieID      3946      3947      3948      3949      3950          3951  \\\n",
      "MovieID                                                                   \n",
      "1        0.103594  0.517544  0.117767  0.152621  0.150568  2.500000e-01   \n",
      "2        0.136752  0.050000  0.213012  0.074787 -0.073529 -2.500000e-01   \n",
      "3        0.215415 -0.032967  0.307597  0.024490  0.424242  0.000000e+00   \n",
      "4        0.133333 -0.333333  0.234398 -0.427350  0.333333  1.110223e-16   \n",
      "5        0.458333  2.000000  0.396450 -0.120968  0.309524  0.000000e+00   \n",
      "\n",
      "MovieID      3952  \n",
      "MovieID            \n",
      "1        0.119849  \n",
      "2        0.069014  \n",
      "3        0.107755  \n",
      "4        0.112536  \n",
      "5       -0.025000  \n",
      "\n",
      "[5 rows x 3706 columns]\n"
     ]
    }
   ],
   "source": [
    "ratings_matrix_mle = ratings_filled.pivot(index='UserID', columns='MovieID', values='Rating')\n",
    "covariance_matrix_mle = ratings_matrix_mle.cov()\n",
    "\n",
    "print(\"Covariance Matrix (MLE):\")\n",
    "print(covariance_matrix_mle.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.2: Determine the top 5-peers and top 10-peers for each of the target items (I1 and I2) using the transformed representation (covariance matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 peers for I1 (MovieID: 127): MovieID\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "5   NaN\n",
      "6   NaN\n",
      "Name: 127, dtype: float64\n",
      "Top 5 peers for I2 (MovieID: 133): MovieID\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "5   NaN\n",
      "6   NaN\n",
      "Name: 133, dtype: float64\n",
      "Top 10 peers for I1 (MovieID: 127): MovieID\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8    NaN\n",
      "9    NaN\n",
      "10   NaN\n",
      "11   NaN\n",
      "Name: 127, dtype: float64\n",
      "Top 10 peers for I2 (MovieID: 133): MovieID\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8    NaN\n",
      "9    NaN\n",
      "10   NaN\n",
      "11   NaN\n",
      "Name: 133, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_5_peers_mle_I1 = covariance_matrix_mle[I1].sort_values(ascending=False).iloc[1:6]  \n",
    "top_5_peers_mle_I2 = covariance_matrix_mle[I2].sort_values(ascending=False).iloc[1:6] \n",
    "\n",
    "top_10_peers_mle_I1 = covariance_matrix_mle[I1].sort_values(ascending=False).iloc[1:11]  \n",
    "top_10_peers_mle_I2 = covariance_matrix_mle[I2].sort_values(ascending=False).iloc[1:11]  \n",
    "\n",
    "print(f\"Top 5 peers for I1 (MovieID: {I1}): {top_5_peers_mle_I1}\")\n",
    "print(f\"Top 5 peers for I2 (MovieID: {I2}): {top_5_peers_mle_I2}\")\n",
    "print(f\"Top 10 peers for I1 (MovieID: {I1}): {top_10_peers_mle_I1}\")\n",
    "print(f\"Top 10 peers for I2 (MovieID: {I2}): {top_10_peers_mle_I2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.3: Determine reduced dimensional space for each user in case of using the top 5-peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dimensional space (Top 5 peers - MLE):\n",
      "[[-0.70905081 -0.27783914]\n",
      " [-0.70905081 -0.27783914]\n",
      " [-0.70905081 -0.27783914]\n",
      " [-0.70905081 -0.27783914]\n",
      " [ 1.21437332 -0.82227991]]\n"
     ]
    }
   ],
   "source": [
    "top_5_peers_I1_and_I2_mle = list(set(top_5_peers_mle_I1.index) | set(top_5_peers_mle_I2.index)) \n",
    "ratings_reduced_5_mle = ratings_matrix_mle[top_5_peers_I1_and_I2_mle].fillna(0)\n",
    "pca_5_mle = PCA(n_components=2)\n",
    "ratings_reduced_5_mle_pca = pca_5_mle.fit_transform(ratings_reduced_5_mle)\n",
    "\n",
    "print(\"Reduced dimensional space (Top 5 peers - MLE):\")\n",
    "print(ratings_reduced_5_mle_pca[:5])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.4: Use the results from point 3.3.3 to compute the rating predictions of the original missing rating for each of the target items (I1 and I2) using the top 5-peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for I1 (using top 5 peers - MLE): UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n",
      "Predicted rating for I2 (using top 5 peers - MLE): UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predicted_rating_I1_5_mle = ratings_reduced_5_mle[top_5_peers_mle_I1.index].mean(axis=1)\n",
    "predicted_rating_I2_5_mle = ratings_reduced_5_mle[top_5_peers_mle_I2.index].mean(axis=1)\n",
    "\n",
    "print(f\"Predicted rating for I1 (using top 5 peers - MLE): {predicted_rating_I1_5_mle[:5]}\")\n",
    "print(f\"Predicted rating for I2 (using top 5 peers - MLE): {predicted_rating_I2_5_mle[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.5: Determine reduced dimensional space for each user in case of using the top 10-peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dimensional space (Top 10 peers - MLE):\n",
      "[[-1.15850786  0.00702471]\n",
      " [-1.15850786  0.00702471]\n",
      " [-1.15850786  0.00702471]\n",
      " [-1.15850786  0.00702471]\n",
      " [-0.12305775 -1.27991222]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_10_peers_I1_and_I2_mle = list(set(top_10_peers_mle_I1.index) | set(top_10_peers_mle_I2.index)) \n",
    "ratings_reduced_10_mle = ratings_matrix_mle[top_10_peers_I1_and_I2_mle].fillna(0)\n",
    "\n",
    "pca_10_mle = PCA(n_components=2)\n",
    "ratings_reduced_10_mle_pca = pca_10_mle.fit_transform(ratings_reduced_10_mle)\n",
    "\n",
    "print(\"Reduced dimensional space (Top 10 peers - MLE):\")\n",
    "print(ratings_reduced_10_mle_pca[:5])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.6: Use the results from point 3.3.5 to compute the rating predictions of the original missing rating for each of the target items (I1 and I2) using the top 10-peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for I1 (using top 10 peers - MLE): UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n",
      "Predicted rating for I2 (using top 10 peers - MLE): UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_rating_I1_10_mle = ratings_reduced_10_mle[top_10_peers_mle_I1.index].mean(axis=1)\n",
    "predicted_rating_I2_10_mle = ratings_reduced_10_mle[top_10_peers_mle_I2.index].mean(axis=1)\n",
    "\n",
    "print(f\"Predicted rating for I1 (using top 10 peers - MLE): {predicted_rating_I1_10_mle[:5]}\")\n",
    "print(f\"Predicted rating for I2 (using top 10 peers - MLE): {predicted_rating_I2_10_mle[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.7: Compare the results of point 3.3.3 with results of point 3.3.6. Comment on your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of predicted ratings for I1:\n",
      "Top 5: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n",
      "Top 10: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n",
      "Comparison of predicted ratings for I2:\n",
      "Top 5: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n",
      "Top 10: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Comparison of predicted ratings for I1:\\nTop 5: {predicted_rating_I1_5_mle[:5]}\\nTop 10: {predicted_rating_I1_10_mle[:5]}\")\n",
    "print(f\"Comparison of predicted ratings for I2:\\nTop 5: {predicted_rating_I2_5_mle[:5]}\\nTop 10: {predicted_rating_I2_10_mle[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.8: Compare the results of point 3.2.9 with results of point 3.3.4. Comment on your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of predicted ratings for I1 (PCA vs MLE):\n",
      "PCA Top 5: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n",
      "MLE Top 5: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n",
      "Comparison of predicted ratings for I2 (PCA vs MLE):\n",
      "PCA Top 5: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n",
      "MLE Top 5: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.4\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Comparison of predicted ratings for I1 (PCA vs MLE):\\nPCA Top 5: {predicted_rating_I1_5[:5]}\\nMLE Top 5: {predicted_rating_I1_5_mle[:5]}\")\n",
    "print(f\"Comparison of predicted ratings for I2 (PCA vs MLE):\\nPCA Top 5: {predicted_rating_I2_5[:5]}\\nMLE Top 5: {predicted_rating_I2_5_mle[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.9: Compare the results of point 3.2.11 with results of point 3.3.6. Comment on your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of predicted ratings for I1 (PCA vs MLE):\n",
      "PCA Top 10: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n",
      "MLE Top 10: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n",
      "Comparison of predicted ratings for I2 (PCA vs MLE):\n",
      "PCA Top 10: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n",
      "MLE Top 10: UserID\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.2\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Comparison of predicted ratings for I1 (PCA vs MLE):\\nPCA Top 10: {predicted_rating_I1_10[:5]}\\nMLE Top 10: {predicted_rating_I1_10_mle[:5]}\")\n",
    "print(f\"Comparison of predicted ratings for I2 (PCA vs MLE):\\nPCA Top 10: {predicted_rating_I2_10[:5]}\\nMLE Top 10: {predicted_rating_I2_10_mle[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Singular Value Decomposition (SVD) method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.1 Calculate the average rating for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ratings for each item:\n",
      "MovieID\n",
      "1    4.146846\n",
      "2    3.201141\n",
      "3    3.016736\n",
      "4    2.729412\n",
      "5    3.006757\n",
      "Name: Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "average_item_ratings = ratings_filled.groupby('MovieID')['Rating'].mean()\n",
    "\n",
    "print(\"Average ratings for each item:\")\n",
    "print(average_item_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.2 Use the mean-filling method to replace unspecified ratings for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings matrix after mean-filling:\n",
      "MovieID  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "UserID                                                               ...   \n",
      "1         5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "5         NaN   NaN   NaN   NaN   NaN   2.0   NaN   NaN   NaN   NaN  ...   \n",
      "\n",
      "MovieID  3943  3944  3945  3946  3947  3948  3949  3950  3951  3952  \n",
      "UserID                                                               \n",
      "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[5 rows x 3706 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ratings_filled_mean = ratings_filled.copy()\n",
    "ratings_filled_mean['Rating'] = ratings_filled_mean.apply(\n",
    "    lambda row: row['Rating'] if pd.notna(row['Rating']) else average_item_ratings[row['MovieID']], axis=1)\n",
    "\n",
    "ratings_matrix_filled = ratings_filled_mean.pivot(index='UserID', columns='MovieID', values='Rating')\n",
    "\n",
    "print(\"Ratings matrix after mean-filling:\")\n",
    "print(ratings_matrix_filled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.3: Compute the eigenvalues (λ1, λ2, λ3, ...) and their corresponding eigenvectors (U1, U2, U3, ...) of the ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [1893.21055869  671.34356538  574.85275997  518.08422502  444.85478082]\n",
      "First 5 eigenvectors (U): [[-0.00471786  0.00164551  0.00267141  0.00137288  0.01872592]\n",
      " [-0.00928856 -0.00269782  0.00038215 -0.00709548 -0.00676515]\n",
      " [-0.00501018 -0.00334292 -0.00334366 -0.0030347   0.01176653]\n",
      " ...\n",
      " [-0.00138885  0.00181339 -0.00011879  0.0005557   0.00488343]\n",
      " [-0.00700793  0.0187647  -0.01071225  0.00858309  0.0219811 ]\n",
      " [-0.01896102  0.04080244 -0.00304316 -0.01862121 -0.00312631]]\n",
      "First 5 eigenvectors (Vt): [[-0.07013714 -0.02354382 -0.01376584 ... -0.00261526 -0.00116636\n",
      "  -0.01325659]\n",
      " [-0.02094015 -0.02979245 -0.0167039  ...  0.0018744   0.00226511\n",
      "   0.00502213]\n",
      " [ 0.03016472 -0.01018907  0.01257242 ...  0.00178319  0.00352092\n",
      "   0.02235768]\n",
      " [-0.00486156  0.03109033  0.02714274 ... -0.00036543 -0.0011091\n",
      "  -0.01275768]\n",
      " [ 0.12477815  0.00958079  0.0058329  ... -0.00526835 -0.00086585\n",
      "  -0.01589169]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "U, S, Vt = np.linalg.svd(ratings_matrix_filled.fillna(0), full_matrices=False)\n",
    "\n",
    "eigenvalues = S\n",
    "\n",
    "eigenvectors_u = U\n",
    "eigenvectors_v = Vt\n",
    "\n",
    "print(\"Eigenvalues:\", eigenvalues[:5])\n",
    "print(\"First 5 eigenvectors (U):\", eigenvectors_u[:, :5])\n",
    "print(\"First 5 eigenvectors (Vt):\", eigenvectors_v[:5, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.4: Check if the set of eigenvectors are mutually orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthogonality check (should be close to 0 off-diagonal):\n",
      "[[ 1.00000000e+00 -5.55111512e-17  6.50521303e-17 ... -1.06251813e-17\n",
      "   8.00954355e-18 -7.58941521e-19]\n",
      " [-5.55111512e-17  1.00000000e+00 -2.32236105e-16 ...  2.11419424e-18\n",
      "   3.36102673e-18  3.30681663e-18]\n",
      " [ 6.50521303e-17 -2.32236105e-16  1.00000000e+00 ...  1.08420217e-18\n",
      "   2.16840434e-18 -8.67361738e-19]\n",
      " ...\n",
      " [-1.06251813e-17  2.11419424e-18  1.08420217e-18 ...  1.00000000e+00\n",
      "  -5.70290343e-17  3.90312782e-17]\n",
      " [ 8.00954355e-18  3.36102673e-18  2.16840434e-18 ... -5.70290343e-17\n",
      "   1.00000000e+00  3.10081821e-17]\n",
      " [-7.58941521e-19  3.30681663e-18 -8.67361738e-19 ...  3.90312782e-17\n",
      "   3.10081821e-17  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "orthogonality_check = np.dot(eigenvectors_u.T, eigenvectors_u)\n",
    "\n",
    "print(\"Orthogonality check (should be close to 0 off-diagonal):\")\n",
    "print(orthogonality_check)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.5: Perform Vector Normalization if the eigenvectors are not orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not np.allclose(orthogonality_check, np.eye(len(orthogonality_check))):\n",
    "    eigenvectors_u = np.linalg.qr(eigenvectors_u)[0]  \n",
    "\n",
    "    print(\"Eigenvectors after orthogonalization:\")\n",
    "    print(eigenvectors_u[:5, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.6: Check if the eigenvectors are orthonormal (each vector must have magnitude 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnitude of eigenvectors (should be 1):\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "norm_check = np.linalg.norm(eigenvectors_u, axis=0)\n",
    "\n",
    "print(\"Magnitude of eigenvectors (should be 1):\")\n",
    "print(norm_check)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.7: Apply Gram-Schmidt method to convert the eigenvectors into an orthonormal set of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors after Gram-Schmidt orthonormalization:\n",
      "[[-0.00471786  0.00164551  0.00267141 ... -0.01776587  0.00369828\n",
      "  -0.00422689]\n",
      " [-0.00928856 -0.00269782  0.00038215 ...  0.01474961 -0.00965117\n",
      "   0.01119521]\n",
      " [-0.00501018 -0.00334292 -0.00334366 ... -0.00230599 -0.00307979\n",
      "  -0.00582591]\n",
      " [-0.00267746 -0.00129703 -0.00767513 ... -0.03719729  0.00644174\n",
      "   0.02108675]\n",
      " [-0.00889607  0.00382517  0.02209941 ... -0.00329437 -0.00147973\n",
      "   0.00681981]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def gram_schmidt_process(vectors):\n",
    "    orthonormal_vectors = []\n",
    "    for v in vectors.T:\n",
    "        for u in orthonormal_vectors:\n",
    "            v -= np.dot(v, u) * u  \n",
    "        v /= np.linalg.norm(v)  \n",
    "        orthonormal_vectors.append(v)\n",
    "    return np.array(orthonormal_vectors).T\n",
    "\n",
    "eigenvectors_u_orthonormal = gram_schmidt_process(eigenvectors_u)\n",
    "\n",
    "print(\"Eigenvectors after Gram-Schmidt orthonormalization:\")\n",
    "print(eigenvectors_u_orthonormal[:5, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.8: Construct the predicted waiting matrix Z from the eigenvalues on the main diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted waiting matrix (Z):\n",
      "[[1893.21055869    0.            0.            0.            0.        ]\n",
      " [   0.          671.34356538    0.            0.            0.        ]\n",
      " [   0.            0.          574.85275997    0.            0.        ]\n",
      " [   0.            0.            0.          518.08422502    0.        ]\n",
      " [   0.            0.            0.            0.          444.85478082]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Z = np.diag(eigenvalues)\n",
    "\n",
    "print(\"Predicted waiting matrix (Z):\")\n",
    "print(Z[:5, :5])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.9: Construct the items matrix 𝑉 whose columns are the set of orthonormal vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items matrix (V):\n",
      "[[-0.07013714 -0.02094015  0.03016472 -0.00486156  0.12477815]\n",
      " [-0.02354382 -0.02979245 -0.01018907  0.03109033  0.00958079]\n",
      " [-0.01376584 -0.0167039   0.01257242  0.02714274  0.0058329 ]\n",
      " [-0.0053234  -0.00296276  0.01235569  0.01507195 -0.0026277 ]\n",
      " [-0.00971651 -0.01348858  0.01247469  0.02888498  0.00431142]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "items_matrix = eigenvectors_v.T\n",
    "\n",
    "print(\"Items matrix (V):\")\n",
    "print(items_matrix[:5, :5])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.10: Construct the predicted user matrix 𝑈 whose columns are the predicted vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users matrix (U):\n",
      "[[-0.00471786  0.00164551  0.00267141  0.00137288  0.01872592]\n",
      " [-0.00928856 -0.00269782  0.00038215 -0.00709548 -0.00676515]\n",
      " [-0.00501018 -0.00334292 -0.00334366 -0.0030347   0.01176653]\n",
      " [-0.00267746 -0.00129703 -0.00767513 -0.00727068  0.0020769 ]\n",
      " [-0.00889607  0.00382517  0.02209941 -0.0184782  -0.00481466]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "users_matrix = eigenvectors_u_orthonormal\n",
    "\n",
    "print(\"Users matrix (U):\")\n",
    "print(users_matrix[:5, :5])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.11: Use the results from points 3.4.8 to 3.4.10 to construct the newly reduced rating matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed rating matrix (R = U Z V^T):\n",
      "[[ 1.26112513  0.60642308 -0.05374419  1.01412053 -0.4537866 ]\n",
      " [ 1.93248762 -0.32874299 -0.45476319  0.81237333 -2.06747525]\n",
      " [ 0.7226417  -0.24510323 -0.94350653 -0.94320407 -0.71339379]\n",
      " [ 0.24257233  0.60698915  0.04299004 -0.41757629 -0.28051981]\n",
      " [ 1.74019636 -0.5079428  -1.08920025 -0.34960232 -2.10334771]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "R_reduced = np.dot(np.dot(users_matrix, Z), items_matrix)\n",
    "\n",
    "print(\"Reconstructed rating matrix (R = U Z V^T):\")\n",
    "print(R_reduced[:5, :5]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.12: Use the results from point 3.4.11 to find missing ratings in the original rating matrix for each of the target items (I1 and I2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted ratings for I1 (MovieID: 127) using SVD:\n",
      "[1.50975508 1.64953463 0.78586411 0.52828894 1.56169789]\n",
      "Predicted ratings for I2 (MovieID: 133) using SVD:\n",
      "[ 0.53995994  1.3911938  -0.09262471  0.05804123 -1.17768289]\n"
     ]
    }
   ],
   "source": [
    "user_indices = ratings_matrix_filled.index - 1  \n",
    "\n",
    "predicted_rating_I1_svd = R_reduced[user_indices, I1_zero_indexed]\n",
    "predicted_rating_I2_svd = R_reduced[user_indices, I2_zero_indexed]\n",
    "\n",
    "print(f\"Predicted ratings for I1 (MovieID: {I1}) using SVD:\")\n",
    "print(predicted_rating_I1_svd[:5]) \n",
    "\n",
    "print(f\"Predicted ratings for I2 (MovieID: {I2}) using SVD:\")\n",
    "print(predicted_rating_I2_svd[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

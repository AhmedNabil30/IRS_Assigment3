{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "IiYl8HHCk6wh",
        "outputId": "aec48dc9-0fe1-485b-fca4-5a8c00c2abe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Users (Tnu): 100\n",
            "Total Number of Items (Tai): 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity of the matrix: 0.488\n",
            "Average Rating: 2.8\n",
            "Bias Check: Unbiased\n",
            "Target Items: ['Mufasa: The Lion King', 'Gladiator II']\n",
            "Results saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Your TMDb API key\n",
        "api_key = '6cded85307abb9c31e7482024ed285f6'\n",
        "\n",
        "# Function to fetch popular movies\n",
        "def fetch_popular_movies(api_key, page=1):\n",
        "    url = f'https://api.themoviedb.org/3/movie/popular?api_key={api_key}&language=en-US&page={page}'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        return data['results']\n",
        "    else:\n",
        "        print(f\"Error: Unable to fetch data, status code {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "# Fetch movies\n",
        "movies = fetch_popular_movies(api_key)\n",
        "\n",
        "if movies:\n",
        "    # Step 1: Create a dataset from fetched movies\n",
        "    dataset = [{'title': movie['title'], 'id': movie['id']} for movie in movies]\n",
        "\n",
        "    # Step 2: Adjust ratings to a 1-to-5 scale\n",
        "    for movie in dataset:\n",
        "        movie['rating'] = random.randint(1, 5)  # Assign random ratings for simulation\n",
        "\n",
        "    # Step 3: Count total number of users\n",
        "    Tnu = 100  # Simulating 100 users for this example\n",
        "    print(f\"Total Number of Users (Tnu): {Tnu}\")\n",
        "\n",
        "    # Step 4: Count total number of items\n",
        "    Tai = len(dataset)\n",
        "    print(f\"Total Number of Items (Tai): {Tai}\")\n",
        "\n",
        "    # Step 5: Count number of ratings per product\n",
        "    ratings_count = {movie['id']: random.randint(1, Tnu) for movie in dataset}\n",
        "    for movie in dataset:\n",
        "        movie['ratings_count'] = ratings_count[movie['id']]\n",
        "\n",
        "    # Step 6: Draw the distribution of ratings\n",
        "    rating_values = [movie['rating'] for movie in dataset]\n",
        "    plt.hist(rating_values, bins=range(1, 7), align='left', edgecolor='black')\n",
        "    plt.xlabel(\"Rating\")\n",
        "    plt.ylabel(\"Count of Ratings\")\n",
        "    plt.title(\"Distribution of Ratings\")\n",
        "    plt.show()\n",
        "\n",
        "    # Check sparsity\n",
        "    sparsity = sum(ratings_count.values()) / (Tnu * Tai)\n",
        "    print(f\"Sparsity of the matrix: {1 - sparsity}\")\n",
        "\n",
        "    # Bias check\n",
        "    avg_rating = sum(rating_values) / len(rating_values)\n",
        "    print(f\"Average Rating: {avg_rating}\")\n",
        "    print(f\"Bias Check: {'Biased' if avg_rating > 3 else 'Unbiased'}\")\n",
        "\n",
        "    # Step 7: Choose the two lowest rated items\n",
        "    sorted_movies = sorted(dataset, key=lambda x: x['rating'])\n",
        "    target_items = sorted_movies[:2]\n",
        "    print(f\"Target Items: {[item['title'] for item in target_items]}\")\n",
        "\n",
        "    # Step 8: Save results for later use\n",
        "    results = {\n",
        "        \"Tnu\": Tnu,\n",
        "        \"Tai\": Tai,\n",
        "        \"ratings_count\": ratings_count,\n",
        "        \"rating_distribution\": rating_values,\n",
        "        \"target_items\": target_items\n",
        "    }\n",
        "\n",
        "    print(\"Results saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Simulated dataset\n",
        "np.random.seed(42)\n",
        "users = [f'User_{i}' for i in range(1, 101)]  # 100 Users\n",
        "items = [f'Item_{i}' for i in range(1, 21)]  # 20 Items\n",
        "ratings_matrix = np.random.randint(1, 6, size=(len(users), len(items))).astype(float)\n",
        "\n",
        "# Introduce missing values (simulate sparsity)\n",
        "missing_indices = np.random.choice(ratings_matrix.size, size=int(0.3 * ratings_matrix.size), replace=False)\n",
        "ratings_matrix.ravel()[missing_indices] = np.nan\n",
        "\n",
        "# Convert to DataFrame\n",
        "ratings_df = pd.DataFrame(ratings_matrix, index=users, columns=items)\n",
        "\n",
        "# Target items (I1 and I2 correspond to 'Item_11' and 'Item_12')\n",
        "target_items = ['Item_11', 'Item_12']\n",
        "\n",
        "# 3.2.1. Calculate the average rating for each target item\n",
        "target_item_means = ratings_df[target_items].mean()\n",
        "print(f\"Average Ratings for Target Items:\\n{target_item_means}\\n\")\n",
        "\n",
        "# 3.2.2. Replace missing ratings with mean values (mean-filling)\n",
        "ratings_filled = ratings_df.copy()\n",
        "for item in ratings_filled.columns:\n",
        "    ratings_filled[item].fillna(ratings_filled[item].mean(), inplace=True)\n",
        "\n",
        "# 3.2.3. Calculate the average rating for each item\n",
        "item_means = ratings_filled.mean()\n",
        "print(f\"Average Ratings for Each Item:\\n{item_means}\\n\")\n",
        "\n",
        "# 3.2.4. Calculate the difference between ratings and the mean rating of each item\n",
        "ratings_diff = ratings_filled.subtract(item_means, axis=1)\n",
        "\n",
        "# 3.2.5. Compute covariance for each two items\n",
        "cov_matrix = ratings_diff.cov()\n",
        "\n",
        "# 3.2.6. Generate the covariance matrix\n",
        "print(f\"Covariance Matrix:\\n{cov_matrix}\\n\")\n",
        "\n",
        "# 3.2.7. Determine the top 5 and top 10 peers for each target item\n",
        "top_5_peers = {}\n",
        "top_10_peers = {}\n",
        "for item in target_items:\n",
        "    sorted_peers = cov_matrix[item].sort_values(ascending=False).iloc[1:]  # Exclude the item itself\n",
        "    top_5_peers[item] = sorted_peers.head(5).index.tolist()\n",
        "    top_10_peers[item] = sorted_peers.head(10).index.tolist()\n",
        "\n",
        "print(f\"Top 5 Peers:\\n{top_5_peers}\\n\")\n",
        "print(f\"Top 10 Peers:\\n{top_10_peers}\\n\")\n",
        "\n",
        "# 3.2.8. Reduced dimensional space for each user (top 5 peers)\n",
        "top_5_space = ratings_filled[top_5_peers[target_items[0]] + top_5_peers[target_items[1]]]\n",
        "\n",
        "# 3.2.9. Compute rating predictions for target items using top 5 peers\n",
        "predictions_5_peers = {}\n",
        "for item in target_items:\n",
        "    peer_ratings = ratings_filled[top_5_peers[item]]\n",
        "    peer_avg_ratings = peer_ratings.mean(axis=1)\n",
        "    predictions_5_peers[item] = peer_avg_ratings\n",
        "\n",
        "print(f\"Predictions using Top 5 Peers:\\n{predictions_5_peers}\\n\")\n",
        "\n",
        "# 3.2.10. Reduced dimensional space for each user (top 10 peers)\n",
        "top_10_space = ratings_filled[top_10_peers[target_items[0]] + top_10_peers[target_items[1]]]\n",
        "\n",
        "# 3.2.11. Compute rating predictions for target items using top 10 peers\n",
        "predictions_10_peers = {}\n",
        "for item in target_items:\n",
        "    peer_ratings = ratings_filled[top_10_peers[item]]\n",
        "    peer_avg_ratings = peer_ratings.mean(axis=1)\n",
        "    predictions_10_peers[item] = peer_avg_ratings\n",
        "\n",
        "print(f\"Predictions using Top 10 Peers:\\n{predictions_10_peers}\\n\")\n",
        "\n",
        "# 3.2.12. Compare results of Top 5 Peers vs Top 10 Peers\n",
        "comparison = {}\n",
        "for item in target_items:\n",
        "    comparison[item] = {\n",
        "        \"Top 5 Predictions Mean\": np.mean(predictions_5_peers[item]),\n",
        "        \"Top 10 Predictions Mean\": np.mean(predictions_10_peers[item]),\n",
        "    }\n",
        "\n",
        "print(f\"Comparison of Predictions:\\n{comparison}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kviyySYBlaSE",
        "outputId": "7d995dcd-6067-437b-8384-eb2661039ea5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Ratings for Target Items:\n",
            "Item_11    2.868852\n",
            "Item_12    2.692308\n",
            "dtype: float64\n",
            "\n",
            "Average Ratings for Each Item:\n",
            "Item_1     2.961538\n",
            "Item_2     3.220588\n",
            "Item_3     3.064935\n",
            "Item_4     3.089744\n",
            "Item_5     3.109375\n",
            "Item_6     2.913043\n",
            "Item_7     3.042857\n",
            "Item_8     3.037975\n",
            "Item_9     2.985294\n",
            "Item_10    2.920635\n",
            "Item_11    2.868852\n",
            "Item_12    2.692308\n",
            "Item_13    2.824324\n",
            "Item_14    2.971429\n",
            "Item_15    3.261538\n",
            "Item_16    3.164179\n",
            "Item_17    2.887324\n",
            "Item_18    3.063492\n",
            "Item_19    2.971831\n",
            "Item_20    3.025316\n",
            "dtype: float64\n",
            "\n",
            "Covariance Matrix:\n",
            "           Item_1    Item_2    Item_3    Item_4    Item_5    Item_6    Item_7  \\\n",
            "Item_1   1.483683 -0.102867 -0.317652 -0.097050  0.095899 -0.022888 -0.100089   \n",
            "Item_2  -0.102867  1.572638 -0.252076 -0.024456  0.140068  0.164070 -0.137357   \n",
            "Item_3  -0.317652 -0.252076  1.622983  0.008027 -0.164174 -0.254675 -0.063262   \n",
            "Item_4  -0.097050 -0.024456  0.008027  1.417897  0.068412  0.142292 -0.268957   \n",
            "Item_5   0.095899  0.140068 -0.164174  0.068412  1.335701 -0.062905 -0.124364   \n",
            "Item_6  -0.022888  0.164070 -0.254675  0.142292 -0.062905  1.449275 -0.044520   \n",
            "Item_7  -0.100089 -0.137357 -0.063262 -0.268957 -0.124364 -0.044520  1.180519   \n",
            "Item_8  -0.044864 -0.058316  0.029496  0.066784  0.134508  0.102083 -0.167914   \n",
            "Item_9   0.058138 -0.081787  0.261536  0.053986 -0.283023 -0.034081 -0.210825   \n",
            "Item_10  0.093555  0.031904  0.161504 -0.078136 -0.045369  0.116897  0.184979   \n",
            "Item_11 -0.296502  0.183805  0.112640 -0.071125 -0.104094  0.089124  0.112374   \n",
            "Item_12 -0.192188  0.157366 -0.174805  0.004423  0.093629 -0.147123 -0.065990   \n",
            "Item_13  0.071778 -0.182691 -0.047048  0.157376  0.146371  0.115645 -0.049374   \n",
            "Item_14  0.028971 -0.210254 -0.073975 -0.064528 -0.129095  0.186775  0.111058   \n",
            "Item_15 -0.280378  0.149963  0.046687 -0.028398  0.072200 -0.028114 -0.057858   \n",
            "Item_16  0.088526 -0.012934 -0.225237 -0.092989 -0.054507  0.115418  0.126215   \n",
            "Item_17 -0.028399  0.174657 -0.280820  0.050020  0.349621 -0.078915 -0.089631   \n",
            "Item_18  0.084224 -0.006576 -0.097404 -0.068851 -0.077754  0.127235  0.127765   \n",
            "Item_19 -0.034079 -0.212374  0.120322 -0.002678  0.128272 -0.106156  0.000268   \n",
            "Item_20  0.183377 -0.279071  0.233592  0.169770 -0.079661 -0.208574  0.231392   \n",
            "\n",
            "           Item_8    Item_9   Item_10   Item_11   Item_12   Item_13   Item_14  \\\n",
            "Item_1  -0.044864  0.058138  0.093555 -0.296502 -0.192188  0.071778  0.028971   \n",
            "Item_2  -0.058316 -0.081787  0.031904  0.183805  0.157366 -0.182691 -0.210254   \n",
            "Item_3   0.029496  0.261536  0.161504  0.112640 -0.174805 -0.047048 -0.073975   \n",
            "Item_4   0.066784  0.053986 -0.078136 -0.071125  0.004423  0.157376 -0.064528   \n",
            "Item_5   0.134508 -0.283023 -0.045369 -0.104094  0.093629  0.146371 -0.129095   \n",
            "Item_6   0.102083 -0.034081  0.116897  0.089124 -0.147123  0.115645  0.186775   \n",
            "Item_7  -0.167914 -0.210825  0.184979  0.112374 -0.065990 -0.049374  0.111058   \n",
            "Item_8   1.524102  0.006795  0.035614  0.058514 -0.071779  0.104499  0.152918   \n",
            "Item_9   0.006795  1.484700  0.100442 -0.038921  0.205460  0.128511 -0.048557   \n",
            "Item_10  0.035614  0.100442  1.420234 -0.230775  0.053884 -0.195314  0.175698   \n",
            "Item_11  0.058514 -0.038921 -0.230775  1.060109 -0.170303 -0.199487  0.028581   \n",
            "Item_12 -0.071779  0.205460  0.053884 -0.170303  1.473193  0.077837 -0.151604   \n",
            "Item_13  0.104499  0.128511 -0.195314 -0.199487  0.077837  1.582992  0.034831   \n",
            "Item_14  0.152918 -0.048557  0.175698  0.028581 -0.151604  0.034831  1.231746   \n",
            "Item_15  0.006015 -0.063303 -0.063053  0.043171  0.154707  0.039913  0.028083   \n",
            "Item_16  0.078904  0.149429  0.166158 -0.214126  0.034420 -0.071353 -0.027447   \n",
            "Item_17  0.050714  0.035412  0.145569  0.064760  0.314642  0.122729  0.168628   \n",
            "Item_18 -0.344297 -0.044434 -0.227895 -0.012495 -0.284555 -0.087934  0.051531   \n",
            "Item_19  0.030281 -0.172037 -0.071683  0.153157 -0.428740 -0.085641  0.016877   \n",
            "Item_20 -0.142081  0.011299 -0.040136 -0.161409 -0.105072  0.209313  0.229770   \n",
            "\n",
            "          Item_15   Item_16   Item_17   Item_18   Item_19   Item_20  \n",
            "Item_1  -0.280378  0.088526 -0.028399  0.084224 -0.034079  0.183377  \n",
            "Item_2   0.149963 -0.012934  0.174657 -0.006576 -0.212374 -0.279071  \n",
            "Item_3   0.046687 -0.225237 -0.280820 -0.097404  0.120322  0.233592  \n",
            "Item_4  -0.028398 -0.092989  0.050020 -0.068851 -0.002678  0.169770  \n",
            "Item_5   0.072200 -0.054507  0.349621 -0.077754  0.128272 -0.079661  \n",
            "Item_6  -0.028114  0.115418 -0.078915  0.127235 -0.106156 -0.208574  \n",
            "Item_7  -0.057858  0.126215 -0.089631  0.127765  0.000268  0.231392  \n",
            "Item_8   0.006015  0.078904  0.050714 -0.344297  0.030281 -0.142081  \n",
            "Item_9  -0.063303  0.149429  0.035412 -0.044434 -0.172037  0.011299  \n",
            "Item_10 -0.063053  0.166158  0.145569 -0.227895 -0.071683 -0.040136  \n",
            "Item_11  0.043171 -0.214126  0.064760 -0.012495  0.153157 -0.161409  \n",
            "Item_12  0.154707  0.034420  0.314642 -0.284555 -0.428740 -0.105072  \n",
            "Item_13  0.039913 -0.071353  0.122729 -0.087934 -0.085641  0.209313  \n",
            "Item_14  0.028083 -0.027447  0.168628  0.051531  0.016877  0.229770  \n",
            "Item_15  1.419736 -0.188043  0.079215  0.062819  0.057231  0.026272  \n",
            "Item_16 -0.188043  1.426202  0.024438 -0.020915  0.052518  0.089474  \n",
            "Item_17  0.079215  0.024438  1.506046 -0.122517 -0.045281  0.126766  \n",
            "Item_18  0.062819 -0.020915 -0.122517  1.209556 -0.125911 -0.034350  \n",
            "Item_19  0.057231  0.052518 -0.045281 -0.125911  1.655997 -0.018264  \n",
            "Item_20  0.026272  0.089474  0.126766 -0.034350 -0.018264  1.474236  \n",
            "\n",
            "Top 5 Peers:\n",
            "{'Item_11': ['Item_2', 'Item_19', 'Item_3', 'Item_7', 'Item_6'], 'Item_12': ['Item_17', 'Item_9', 'Item_2', 'Item_15', 'Item_5']}\n",
            "\n",
            "Top 10 Peers:\n",
            "{'Item_11': ['Item_2', 'Item_19', 'Item_3', 'Item_7', 'Item_6', 'Item_17', 'Item_8', 'Item_15', 'Item_14', 'Item_18'], 'Item_12': ['Item_17', 'Item_9', 'Item_2', 'Item_15', 'Item_5', 'Item_13', 'Item_10', 'Item_16', 'Item_4', 'Item_7']}\n",
            "\n",
            "Predictions using Top 5 Peers:\n",
            "{'Item_11': User_1      2.639713\n",
            "User_2      3.208571\n",
            "User_3      2.991180\n",
            "User_4      3.644118\n",
            "User_5      2.382609\n",
            "              ...   \n",
            "User_96     3.038484\n",
            "User_97     3.782609\n",
            "User_98     2.602938\n",
            "User_99     2.644118\n",
            "User_100    3.600000\n",
            "Length: 100, dtype: float64, 'Item_12': User_1      3.315359\n",
            "User_2      3.177465\n",
            "User_3      2.621875\n",
            "User_4      3.044118\n",
            "User_5      2.399340\n",
            "              ...   \n",
            "User_96     3.844118\n",
            "User_97     3.600000\n",
            "User_98     2.797059\n",
            "User_99     2.895765\n",
            "User_100    2.800000\n",
            "Length: 100, dtype: float64}\n",
            "\n",
            "Predictions using Top 10 Peers:\n",
            "{'Item_11': User_1      2.949503\n",
            "User_2      3.190161\n",
            "User_3      3.192733\n",
            "User_4      3.319202\n",
            "User_5      2.177180\n",
            "              ...   \n",
            "User_96     3.419242\n",
            "User_97     3.495102\n",
            "User_98     2.801469\n",
            "User_99     2.740743\n",
            "User_100    3.303492\n",
            "Length: 100, dtype: float64, 'Item_12': User_1      3.375135\n",
            "User_2      3.384425\n",
            "User_3      2.923048\n",
            "User_4      2.914122\n",
            "User_5      2.708151\n",
            "              ...   \n",
            "User_96     3.414122\n",
            "User_97     3.698850\n",
            "User_98     3.502815\n",
            "User_99     2.755707\n",
            "User_100    2.574496\n",
            "Length: 100, dtype: float64}\n",
            "\n",
            "Comparison of Predictions:\n",
            "{'Item_11': {'Top 5 Predictions Mean': 3.042650981452537, 'Top 10 Predictions Mean': 3.0435012630928058}, 'Item_12': {'Top 5 Predictions Mean': 3.092823951628322, 'Top 10 Predictions Mean': 3.05058588401792}}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-5ac41a8d4231>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  ratings_filled[item].fillna(ratings_filled[item].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Simulated dataset (same as Part 1)\n",
        "np.random.seed(42)\n",
        "users = [f'User_{i}' for i in range(1, 101)]  # 100 Users\n",
        "items = [f'Item_{i}' for i in range(1, 21)]  # 20 Items\n",
        "ratings_matrix = np.random.randint(1, 6, size=(len(users), len(items))).astype(float)\n",
        "\n",
        "# Introduce missing values (simulate sparsity)\n",
        "missing_indices = np.random.choice(ratings_matrix.size, size=int(0.3 * ratings_matrix.size), replace=False)\n",
        "ratings_matrix.ravel()[missing_indices] = np.nan\n",
        "\n",
        "# Convert to DataFrame\n",
        "ratings_df = pd.DataFrame(ratings_matrix, index=users, columns=items)\n",
        "\n",
        "# Target items (I1 and I2 correspond to 'Item_11' and 'Item_12')\n",
        "target_items = ['Item_11', 'Item_12']\n",
        "\n",
        "# Function to compute covariance with Maximum Likelihood Estimation\n",
        "def compute_mle_covariance(ratings_df):\n",
        "    items = ratings_df.columns\n",
        "    covariance_matrix = pd.DataFrame(0, index=items, columns=items)\n",
        "\n",
        "    for i in items:\n",
        "        for j in items:\n",
        "            # Find common users with specified ratings\n",
        "            common_ratings = ratings_df[[i, j]].dropna()\n",
        "            if len(common_ratings) > 1:  # At least two users to compute covariance\n",
        "                covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
        "\n",
        "    return covariance_matrix\n",
        "\n",
        "# 3.3.1. Generate the covariance matrix\n",
        "mle_cov_matrix = compute_mle_covariance(ratings_df)\n",
        "print(f\"MLE Covariance Matrix:\\n{mle_cov_matrix}\\n\")\n",
        "\n",
        "# 3.3.2. Determine the top 5 and top 10 peers for each target item\n",
        "top_5_peers = {}\n",
        "top_10_peers = {}\n",
        "for item in target_items:\n",
        "    sorted_peers = mle_cov_matrix[item].sort_values(ascending=False).iloc[1:]  # Exclude the item itself\n",
        "    top_5_peers[item] = sorted_peers.head(5).index.tolist()\n",
        "    top_10_peers[item] = sorted_peers.head(10).index.tolist()\n",
        "\n",
        "print(f\"Top 5 Peers (MLE):\\n{top_5_peers}\\n\")\n",
        "print(f\"Top 10 Peers (MLE):\\n{top_10_peers}\\n\")\n",
        "\n",
        "# 3.3.3. Reduced dimensional space for each user (top 5 peers)\n",
        "top_5_space = ratings_df[top_5_peers[target_items[0]] + top_5_peers[target_items[1]]]\n",
        "\n",
        "# 3.3.4. Compute rating predictions for target items using top 5 peers\n",
        "predictions_5_peers = {}\n",
        "for item in target_items:\n",
        "    peer_ratings = ratings_df[top_5_peers[item]]\n",
        "    peer_avg_ratings = peer_ratings.mean(axis=1)\n",
        "    predictions_5_peers[item] = peer_avg_ratings\n",
        "\n",
        "print(f\"Predictions using Top 5 Peers (MLE):\\n{predictions_5_peers}\\n\")\n",
        "\n",
        "# 3.3.5. Reduced dimensional space for each user (top 10 peers)\n",
        "top_10_space = ratings_df[top_10_peers[target_items[0]] + top_10_peers[target_items[1]]]\n",
        "\n",
        "# 3.3.6. Compute rating predictions for target items using top 10 peers\n",
        "predictions_10_peers = {}\n",
        "for item in target_items:\n",
        "    peer_ratings = ratings_df[top_10_peers[item]]\n",
        "    peer_avg_ratings = peer_ratings.mean(axis=1)\n",
        "    predictions_10_peers[item] = peer_avg_ratings\n",
        "\n",
        "print(f\"Predictions using Top 10 Peers (MLE):\\n{predictions_10_peers}\\n\")\n",
        "\n",
        "# 3.3.7. Compare results of Top 5 Peers vs Top 10 Peers\n",
        "comparison_mle = {}\n",
        "for item in target_items:\n",
        "    comparison_mle[item] = {\n",
        "        \"Top 5 Predictions Mean\": np.nanmean(predictions_5_peers[item]),\n",
        "        \"Top 10 Predictions Mean\": np.nanmean(predictions_10_peers[item]),\n",
        "    }\n",
        "\n",
        "print(f\"Comparison of Predictions (MLE):\\n{comparison_mle}\\n\")\n",
        "\n",
        "# 3.3.8. Compare results of Part 2 (MLE) with Part 1 (Mean-Filling) for Top 5 Peers\n",
        "comparison_part1_part2_5 = {}\n",
        "for item in target_items:\n",
        "    comparison_part1_part2_5[item] = {\n",
        "        \"Mean-Filling (Part 1)\": np.mean(predictions_5_peers[item]),  # Replace this with Part 1 results\n",
        "        \"MLE (Part 2)\": np.mean(predictions_5_peers[item]),\n",
        "    }\n",
        "\n",
        "print(f\"Comparison of Part 1 vs Part 2 (Top 5 Peers):\\n{comparison_part1_part2_5}\\n\")\n",
        "\n",
        "# 3.3.9. Compare results of Part 2 (MLE) with Part 1 (Mean-Filling) for Top 10 Peers\n",
        "comparison_part1_part2_10 = {}\n",
        "for item in target_items:\n",
        "    comparison_part1_part2_10[item] = {\n",
        "        \"Mean-Filling (Part 1)\": np.mean(predictions_10_peers[item]),  # Replace this with Part 1 results\n",
        "        \"MLE (Part 2)\": np.mean(predictions_10_peers[item]),\n",
        "    }\n",
        "\n",
        "print(f\"Comparison of Part 1 vs Part 2 (Top 10 Peers):\\n{comparison_part1_part2_10}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD91m2himlYa",
        "outputId": "b1b11ec0-a0e2-4ac2-9354-de03a0a5e7ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.2035294117647058' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.5438340151957919' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.14890710382513675' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.18778280542986436' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.04354136429608134' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.1928721174004193' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.06646825396825397' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.10691823899371063' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.17156862745098037' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.6717171717171716' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.3505079825834543' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.12643678160919553' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05555555555555552' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.604995374653099' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.1812244897959183' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.056240928882438174' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.1719858156028367' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.06610275689223045' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.29243786356425167' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n",
            "<ipython-input-3-95e84f2d7cb0>:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.2035294117647058' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  covariance_matrix.loc[i, j] = np.cov(common_ratings[i], common_ratings[j])[0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLE Covariance Matrix:\n",
            "           Item_1    Item_2    Item_3    Item_4    Item_5    Item_6  \\\n",
            "Item_1   0.000000 -0.203529 -0.543834 -0.148907  0.187783 -0.043541   \n",
            "Item_2  -0.203529  0.000000 -0.474843 -0.046122  0.323467  0.368182   \n",
            "Item_3  -0.543834 -0.474843  0.000000  0.005553 -0.331429 -0.492017   \n",
            "Item_4  -0.148907 -0.046122  0.005553  0.000000  0.127883  0.253872   \n",
            "Item_5   0.187783  0.323467 -0.331429  0.127883  0.000000 -0.141414   \n",
            "Item_6  -0.043541  0.368182 -0.492017  0.253872 -0.141414  0.000000   \n",
            "Item_7  -0.192872 -0.300532 -0.119013 -0.506289 -0.257971 -0.087347   \n",
            "Item_8  -0.066468 -0.097403  0.050847  0.109466  0.261689  0.187205   \n",
            "Item_9   0.106918 -0.170213  0.487072  0.105870 -0.606765 -0.075798   \n",
            "Item_10  0.171569  0.042424  0.390909 -0.156863 -0.121951  0.257005   \n",
            "Item_11 -0.671717  0.427061  0.222745 -0.151020 -0.266667  0.181707   \n",
            "Item_12 -0.350508  0.409192 -0.372024 -0.009412  0.209302 -0.301418   \n",
            "Item_13  0.126437 -0.367059 -0.078947  0.269141  0.327536  0.237551   \n",
            "Item_14  0.055556 -0.416078 -0.131027 -0.114286 -0.278446  0.398068   \n",
            "Item_15 -0.604995  0.332828  0.093725 -0.063776  0.217949 -0.064251   \n",
            "Item_16  0.181224 -0.038760 -0.431785 -0.175980 -0.115691  0.267287   \n",
            "Item_17 -0.056241  0.361176 -0.535639  0.087719  0.720238 -0.160784   \n",
            "Item_18  0.171986 -0.055128 -0.219324 -0.148936 -0.198780  0.275671   \n",
            "Item_19 -0.066103 -0.458372  0.266591 -0.012066  0.293434 -0.209412   \n",
            "Item_20  0.292438 -0.526205  0.398890  0.288136 -0.163522 -0.375325   \n",
            "\n",
            "               Item_7    Item_8    Item_9   Item_10   Item_11   Item_12  \\\n",
            "Item_1  -1.928721e-01 -0.066468  0.106918  0.171569 -0.671717 -0.350508   \n",
            "Item_2  -3.005319e-01 -0.097403 -0.170213  0.042424  0.427061  0.409192   \n",
            "Item_3  -1.190131e-01  0.050847  0.487072  0.390909  0.222745 -0.372024   \n",
            "Item_4  -5.062893e-01  0.109466  0.105870 -0.156863 -0.151020 -0.009412   \n",
            "Item_5  -2.579710e-01  0.261689 -0.606765 -0.121951 -0.266667  0.209302   \n",
            "Item_6  -8.734694e-02  0.187205 -0.075798  0.257005  0.181707 -0.301418   \n",
            "Item_7   0.000000e+00 -0.330552 -0.416863  0.459146  0.315789 -0.139456   \n",
            "Item_8  -3.305515e-01  0.000000  0.009434  0.078431  0.115691 -0.151596   \n",
            "Item_9  -4.168627e-01  0.009434  0.000000  0.226263 -0.123477  0.482281   \n",
            "Item_10  4.591463e-01  0.078431  0.226263  0.000000 -0.587179  0.130769   \n",
            "Item_11  3.157895e-01  0.115691 -0.123477 -0.587179  0.000000 -0.427800   \n",
            "Item_12 -1.394558e-01 -0.151596  0.482281  0.130769 -0.427800  0.000000   \n",
            "Item_13 -9.154437e-02  0.212644  0.281643 -0.451274 -0.485482  0.175102   \n",
            "Item_14  2.160784e-01  0.275649 -0.116096  0.424242  0.066667 -0.310612   \n",
            "Item_15 -1.367663e-01  0.011181 -0.150106 -0.171795  0.098560  0.379268   \n",
            "Item_16  2.715079e-01  0.139724  0.378049  0.427800 -0.518002  0.089431   \n",
            "Item_17 -1.654902e-01  0.090539  0.063137  0.297896  0.129268  0.741417   \n",
            "Item_18  2.984496e-01 -0.701956 -0.092949 -0.591768 -0.054054 -0.644444   \n",
            "Item_19 -5.551115e-17  0.042293 -0.321809 -0.159091  0.348837 -0.912234   \n",
            "Item_20  4.259259e-01 -0.221710  0.017959 -0.061224 -0.324405 -0.208235   \n",
            "\n",
            "          Item_13   Item_14   Item_15   Item_16   Item_17   Item_18  \\\n",
            "Item_1   0.126437  0.055556 -0.604995  0.181224 -0.056241  0.171986   \n",
            "Item_2  -0.367059 -0.416078  0.332828 -0.038760  0.361176 -0.055128   \n",
            "Item_3  -0.078947 -0.131027  0.093725 -0.431785 -0.535639 -0.219324   \n",
            "Item_4   0.269141 -0.114286 -0.063776 -0.175980  0.087719 -0.148936   \n",
            "Item_5   0.327536 -0.278446  0.217949 -0.115691  0.720238 -0.198780   \n",
            "Item_6   0.237551  0.398068 -0.064251  0.267287 -0.160784  0.275671   \n",
            "Item_7  -0.091544  0.216078 -0.136766  0.271508 -0.165490  0.298450   \n",
            "Item_8   0.212644  0.275649  0.011181  0.139724  0.090539 -0.701956   \n",
            "Item_9   0.281643 -0.116096 -0.150106  0.378049  0.063137 -0.092949   \n",
            "Item_10 -0.451274  0.424242 -0.171795  0.427800  0.297896 -0.591768   \n",
            "Item_11 -0.485482  0.066667  0.098560 -0.518002  0.129268 -0.054054   \n",
            "Item_12  0.175102 -0.310612  0.379268  0.089431  0.741417 -0.644444   \n",
            "Item_13  0.000000  0.067119  0.078901 -0.196003  0.241327 -0.235201   \n",
            "Item_14  0.067119  0.000000  0.058081 -0.063529  0.360784  0.124274   \n",
            "Item_15  0.078901  0.058081  0.000000 -0.397980  0.152636  0.144512   \n",
            "Item_16 -0.196003 -0.063529 -0.397980  0.000000 -0.000463 -0.050941   \n",
            "Item_17  0.241327  0.360784  0.152636 -0.000463  0.000000 -0.255128   \n",
            "Item_18 -0.235201  0.124274  0.144512 -0.050941 -0.255128  0.000000   \n",
            "Item_19 -0.160727  0.023810  0.112858  0.126321 -0.088989 -0.262411   \n",
            "Item_20  0.369376  0.423052  0.048980  0.159461  0.219601 -0.056863   \n",
            "\n",
            "              Item_19   Item_20  \n",
            "Item_1  -6.610276e-02  0.292438  \n",
            "Item_2  -4.583719e-01 -0.526205  \n",
            "Item_3   2.665913e-01  0.398890  \n",
            "Item_4  -1.206637e-02  0.288136  \n",
            "Item_5   2.934343e-01 -0.163522  \n",
            "Item_6  -2.094118e-01 -0.375325  \n",
            "Item_7  -5.551115e-17  0.425926  \n",
            "Item_8   4.229323e-02 -0.221710  \n",
            "Item_9  -3.218085e-01  0.017959  \n",
            "Item_10 -1.590909e-01 -0.061224  \n",
            "Item_11  3.488372e-01 -0.324405  \n",
            "Item_12 -9.122340e-01 -0.208235  \n",
            "Item_13 -1.607268e-01  0.369376  \n",
            "Item_14  2.380952e-02  0.423052  \n",
            "Item_15  1.128585e-01  0.048980  \n",
            "Item_16  1.263214e-01  0.159461  \n",
            "Item_17 -8.898944e-02  0.219601  \n",
            "Item_18 -2.624113e-01 -0.056863  \n",
            "Item_19  0.000000e+00 -0.043771  \n",
            "Item_20 -4.377104e-02  0.000000  \n",
            "\n",
            "Top 5 Peers (MLE):\n",
            "{'Item_11': ['Item_19', 'Item_7', 'Item_3', 'Item_6', 'Item_17'], 'Item_12': ['Item_9', 'Item_2', 'Item_15', 'Item_5', 'Item_13']}\n",
            "\n",
            "Top 10 Peers (MLE):\n",
            "{'Item_11': ['Item_19', 'Item_7', 'Item_3', 'Item_6', 'Item_17', 'Item_8', 'Item_15', 'Item_14', 'Item_11', 'Item_18'], 'Item_12': ['Item_9', 'Item_2', 'Item_15', 'Item_5', 'Item_13', 'Item_10', 'Item_16', 'Item_12', 'Item_4', 'Item_7']}\n",
            "\n",
            "Predictions using Top 5 Peers (MLE):\n",
            "{'Item_11': User_1      2.666667\n",
            "User_2      2.666667\n",
            "User_3      4.000000\n",
            "User_4      3.200000\n",
            "User_5      2.666667\n",
            "              ...   \n",
            "User_96     3.500000\n",
            "User_97     3.750000\n",
            "User_98     3.333333\n",
            "User_99     2.500000\n",
            "User_100    3.800000\n",
            "Length: 100, dtype: float64, 'Item_12': User_1      5.00\n",
            "User_2      3.25\n",
            "User_3      2.00\n",
            "User_4      4.00\n",
            "User_5      2.25\n",
            "            ... \n",
            "User_96     3.75\n",
            "User_97     3.75\n",
            "User_98     3.00\n",
            "User_99     2.00\n",
            "User_100    2.25\n",
            "Length: 100, dtype: float64}\n",
            "\n",
            "Predictions using Top 10 Peers (MLE):\n",
            "{'Item_11': User_1      2.750000\n",
            "User_2      3.000000\n",
            "User_3      3.666667\n",
            "User_4      3.375000\n",
            "User_5      2.142857\n",
            "              ...   \n",
            "User_96     3.444444\n",
            "User_97     3.625000\n",
            "User_98     2.750000\n",
            "User_99     2.285714\n",
            "User_100    3.500000\n",
            "Length: 100, dtype: float64, 'Item_12': User_1      3.666667\n",
            "User_2      3.714286\n",
            "User_3      2.500000\n",
            "User_4      3.142857\n",
            "User_5      2.285714\n",
            "              ...   \n",
            "User_96     3.125000\n",
            "User_97     4.125000\n",
            "User_98     3.375000\n",
            "User_99     2.750000\n",
            "User_100    2.000000\n",
            "Length: 100, dtype: float64}\n",
            "\n",
            "Comparison of Predictions (MLE):\n",
            "{'Item_11': {'Top 5 Predictions Mean': 2.965824915824916, 'Top 10 Predictions Mean': 3.0006626984126985}, 'Item_12': {'Top 5 Predictions Mean': 3.0775, 'Top 10 Predictions Mean': 3.007519841269841}}\n",
            "\n",
            "Comparison of Part 1 vs Part 2 (Top 5 Peers):\n",
            "{'Item_11': {'Mean-Filling (Part 1)': 2.965824915824916, 'MLE (Part 2)': 2.965824915824916}, 'Item_12': {'Mean-Filling (Part 1)': 3.0775, 'MLE (Part 2)': 3.0775}}\n",
            "\n",
            "Comparison of Part 1 vs Part 2 (Top 10 Peers):\n",
            "{'Item_11': {'Mean-Filling (Part 1)': 3.0006626984126985, 'MLE (Part 2)': 3.0006626984126985}, 'Item_12': {'Mean-Filling (Part 1)': 3.007519841269841, 'MLE (Part 2)': 3.007519841269841}}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#part 3\n",
        "#3.4.1. Calculate the Average Rating for Each Item\n",
        "# Calculate the average rating for each item\n",
        "average_ratings = ratings_df.mean(axis=0)\n",
        "print(f\"Average Ratings for Each Item:\\n{average_ratings}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClpA5QQUn6mw",
        "outputId": "763c65e5-f666-40fa-bf25-01da91e16b42"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Ratings for Each Item:\n",
            "Item_1     2.961538\n",
            "Item_2     3.220588\n",
            "Item_3     3.064935\n",
            "Item_4     3.089744\n",
            "Item_5     3.109375\n",
            "Item_6     2.913043\n",
            "Item_7     3.042857\n",
            "Item_8     3.037975\n",
            "Item_9     2.985294\n",
            "Item_10    2.920635\n",
            "Item_11    2.868852\n",
            "Item_12    2.692308\n",
            "Item_13    2.824324\n",
            "Item_14    2.971429\n",
            "Item_15    3.261538\n",
            "Item_16    3.164179\n",
            "Item_17    2.887324\n",
            "Item_18    3.063492\n",
            "Item_19    2.971831\n",
            "Item_20    3.025316\n",
            "dtype: float64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.4.2. Use the Mean-Filling Method\n",
        "# Replace missing values with mean ratings\n",
        "mean_filled_ratings = ratings_df.fillna(average_ratings)\n",
        "print(\"Ratings Matrix after Mean-Filling:\\n\", mean_filled_ratings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt-3d39spbSD",
        "outputId": "81ca7d37-94e1-472c-cec5-8a166528bbd0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings Matrix after Mean-Filling:\n",
            "             Item_1    Item_2    Item_3    Item_4    Item_5    Item_6  \\\n",
            "User_1    4.000000  3.220588  3.064935  3.089744  3.109375  2.913043   \n",
            "User_2    2.000000  5.000000  4.000000  3.089744  1.000000  3.000000   \n",
            "User_3    4.000000  1.000000  4.000000  3.089744  3.109375  2.913043   \n",
            "User_4    2.961538  3.220588  5.000000  2.000000  2.000000  4.000000   \n",
            "User_5    5.000000  1.000000  5.000000  5.000000  3.109375  2.913043   \n",
            "...            ...       ...       ...       ...       ...       ...   \n",
            "User_96   5.000000  3.220588  2.000000  1.000000  4.000000  5.000000   \n",
            "User_97   1.000000  4.000000  3.000000  3.000000  4.000000  2.913043   \n",
            "User_98   2.961538  1.000000  5.000000  4.000000  2.000000  1.000000   \n",
            "User_99   2.000000  3.220588  5.000000  3.089744  3.109375  1.000000   \n",
            "User_100  4.000000  4.000000  2.000000  1.000000  2.000000  3.000000   \n",
            "\n",
            "            Item_7    Item_8    Item_9   Item_10   Item_11   Item_12  \\\n",
            "User_1    3.000000  3.000000  2.985294  2.920635  2.868852  3.000000   \n",
            "User_2    3.042857  2.000000  4.000000  4.000000  3.000000  4.000000   \n",
            "User_3    3.042857  5.000000  2.000000  4.000000  2.868852  2.692308   \n",
            "User_4    2.000000  2.000000  4.000000  2.920635  2.868852  2.692308   \n",
            "User_5    1.000000  1.000000  4.000000  2.920635  3.000000  1.000000   \n",
            "...            ...       ...       ...       ...       ...       ...   \n",
            "User_96   2.000000  5.000000  4.000000  2.920635  3.000000  2.000000   \n",
            "User_97   5.000000  3.037975  2.000000  5.000000  4.000000  5.000000   \n",
            "User_98   3.042857  4.000000  2.985294  5.000000  1.000000  2.000000   \n",
            "User_99   2.000000  3.037975  2.000000  2.000000  1.000000  5.000000   \n",
            "User_100  4.000000  2.000000  1.000000  2.920635  5.000000  1.000000   \n",
            "\n",
            "           Item_13   Item_14   Item_15   Item_16   Item_17   Item_18  \\\n",
            "User_1    5.000000  2.971429  3.261538  3.164179  4.000000  3.063492   \n",
            "User_2    2.824324  2.971429  3.000000  5.000000  2.887324  5.000000   \n",
            "User_3    2.824324  2.971429  3.000000  3.164179  4.000000  2.000000   \n",
            "User_4    5.000000  2.971429  5.000000  2.000000  1.000000  4.000000   \n",
            "User_5    3.000000  2.971429  1.000000  3.164179  2.887324  2.000000   \n",
            "...            ...       ...       ...       ...       ...       ...   \n",
            "User_96   4.000000  3.000000  3.000000  5.000000  5.000000  3.000000   \n",
            "User_97   2.824324  3.000000  5.000000  3.164179  3.000000  2.000000   \n",
            "User_98   5.000000  2.000000  4.000000  4.000000  4.000000  1.000000   \n",
            "User_99   2.824324  1.000000  3.261538  3.164179  2.887324  4.000000   \n",
            "User_100  2.824324  2.971429  2.000000  1.000000  5.000000  3.063492   \n",
            "\n",
            "           Item_19   Item_20  \n",
            "User_1    1.000000  4.000000  \n",
            "User_2    1.000000  2.000000  \n",
            "User_3    4.000000  2.000000  \n",
            "User_4    4.000000  3.025316  \n",
            "User_5    2.000000  3.025316  \n",
            "...            ...       ...  \n",
            "User_96   2.971831  4.000000  \n",
            "User_97   4.000000  2.000000  \n",
            "User_98   2.971831  5.000000  \n",
            "User_99   2.000000  3.000000  \n",
            "User_100  5.000000  3.000000  \n",
            "\n",
            "[100 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.4.3. Compute Eigenvalues and Eigenvectors\n",
        "from numpy.linalg import eig\n",
        "\n",
        "# Convert the mean-filled DataFrame to a NumPy array\n",
        "ratings_array = mean_filled_ratings.to_numpy()\n",
        "\n",
        "# Compute eigenvalues and eigenvectors\n",
        "eigenvalues, eigenvectors = eig(np.cov(ratings_array, rowvar=False))\n",
        "print(\"Eigenvalues:\", eigenvalues)\n",
        "print(\"Eigenvectors:\\n\", eigenvectors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As7r2AHlpiOV",
        "outputId": "46fac2d8-eb87-445e-ed48-09d31347aaa0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues: [2.65665233 2.38657587 2.28675773 0.45522261 2.16178676 1.97710415\n",
            " 1.92360098 1.77681622 0.61524099 0.65715421 0.75495315 0.8432728\n",
            " 0.87047296 1.08510144 1.47743105 1.44487314 1.37470281 1.32714144\n",
            " 1.22293507 1.23375071]\n",
            "Eigenvectors:\n",
            " [[-2.23863514e-02  3.46253098e-01 -3.95054667e-01  1.26582225e-01\n",
            "  -6.15926912e-02 -7.22450082e-02 -6.50679168e-02 -3.40535648e-01\n",
            "   3.84792846e-01  1.84981564e-01  7.30815944e-02  2.93268059e-01\n",
            "   1.05120916e-02  2.36289058e-01  1.59547505e-01  3.38052696e-01\n",
            "  -2.68304843e-01  1.11792397e-01 -3.32515342e-02  1.52988550e-01]\n",
            " [ 4.27450124e-01 -3.28965030e-01 -5.68857482e-02  9.00845845e-02\n",
            "   1.30888563e-01  8.44316069e-03 -7.18933735e-03 -1.18271588e-02\n",
            "  -2.28222473e-02  1.43777872e-01 -2.67857137e-01 -2.51310165e-01\n",
            "  -3.00698880e-02  2.65347364e-01  3.28274840e-01  1.42955144e-04\n",
            "  -1.88955003e-02  3.55594245e-02 -5.59348540e-01  1.75086315e-01]\n",
            " [-4.16719166e-01 -4.13109543e-02  5.06852037e-01  2.51840213e-01\n",
            "   1.39647726e-01  1.13568825e-01  1.81941436e-02 -2.07086125e-02\n",
            "   2.84518173e-01  2.47712791e-01  4.66601913e-02 -3.67729302e-03\n",
            "   2.74046139e-01 -2.74809562e-01  1.81897285e-01  1.78191947e-01\n",
            "   5.36795832e-02  1.32751776e-01 -2.92838342e-01 -7.02460559e-02]\n",
            " [ 6.10394705e-02  1.18759326e-01  1.92295960e-01  1.00333932e-01\n",
            "  -2.17673083e-01 -4.50734614e-02 -3.37572677e-01  4.09887855e-02\n",
            "   2.59215843e-01  3.14554109e-02 -1.06301875e-01  3.60090152e-02\n",
            "  -3.37012504e-01  1.36559499e-02  5.08346158e-01 -1.80842680e-01\n",
            "   4.04639536e-01 -1.98614518e-01  2.76158289e-01  7.04987326e-02]\n",
            " [ 2.64623311e-01  2.59613774e-03 -1.53772039e-03 -6.69121674e-02\n",
            "  -4.07163706e-01 -3.79780245e-02  1.79255339e-01 -2.12573407e-01\n",
            "  -3.46786931e-03 -2.97720515e-01 -4.14619120e-01  2.94411748e-01\n",
            "   1.26290178e-01 -4.68866878e-01  6.10835317e-02  1.47399318e-01\n",
            "   1.18385638e-01  1.67630416e-01 -1.34877202e-01 -1.10257442e-01]\n",
            " [ 1.25860103e-01 -6.49992572e-02 -2.68018895e-01  1.16136916e-01\n",
            "  -1.91559608e-02  2.18764306e-01 -4.32232869e-01  4.23076592e-01\n",
            "  -1.75489495e-01  1.16119269e-01  1.23637336e-01  3.82998076e-01\n",
            "   4.01753196e-01 -5.69807762e-03  1.27565633e-01 -1.00131111e-01\n",
            "   8.69395618e-02  2.03989183e-01 -1.81772693e-02 -1.92553395e-01]\n",
            " [-1.66930826e-01 -6.30064752e-04 -1.98344496e-01  4.21797471e-01\n",
            "   1.27503644e-01 -6.47651762e-02  3.26095324e-01  2.73839914e-01\n",
            "   3.63892477e-02  1.16439954e-01 -2.25874969e-01  3.54614024e-01\n",
            "  -4.27378660e-01  4.59141694e-02 -2.28299255e-01 -7.28212186e-02\n",
            "   2.20232973e-01 -7.37791172e-02 -1.95745281e-01 -1.64324671e-01]\n",
            " [ 7.76662851e-02  5.47872516e-02  1.33254481e-01 -6.10665309e-02\n",
            "  -2.91292238e-01  5.39181383e-01 -1.68803615e-01  5.47158546e-02\n",
            "  -1.41537547e-01  3.15624405e-01 -2.83274934e-02  7.59050023e-02\n",
            "  -2.29409260e-01 -1.18771114e-01 -3.28017416e-01  2.29805934e-01\n",
            "  -2.15909784e-02 -1.71617484e-01 -1.07391127e-01  4.09408828e-01]\n",
            " [-1.02510010e-02  2.71790181e-01  2.70752787e-01  6.26273061e-02\n",
            "   3.44104604e-01  1.28789884e-01 -2.48691400e-01 -1.04132508e-01\n",
            "  -2.21001124e-01 -1.85925388e-01 -3.16307093e-01  2.35452120e-01\n",
            "  -2.04649786e-01 -4.26388207e-02  9.94571791e-02 -2.63011328e-01\n",
            "  -5.23238546e-01  5.79105641e-02 -3.13421227e-02 -3.64897632e-02]\n",
            " [ 1.87078954e-02  1.76930305e-01 -5.78983867e-02 -4.15332982e-01\n",
            "   2.41548846e-01  4.49731532e-01  2.77119910e-01  1.17615554e-01\n",
            "  -1.51916998e-03 -1.91914834e-02  6.63053685e-02 -5.18344513e-02\n",
            "  -2.83470754e-01  4.31408501e-02  2.97268671e-01  2.28095809e-01\n",
            "   1.72023932e-01  3.56218186e-01  4.86111952e-02 -2.28790607e-01]\n",
            " [-4.84407488e-02 -3.51509594e-01  7.56834862e-02 -4.66192829e-01\n",
            "  -4.08760633e-02  5.74730952e-02 -3.74415986e-03  1.71104620e-01\n",
            "   4.58882006e-01 -1.47140488e-01  7.48966992e-02  3.56842986e-01\n",
            "  -4.43901756e-02  9.43593499e-02  5.57103824e-04 -7.32822536e-02\n",
            "  -2.42898456e-01 -3.57257298e-01 -1.83511324e-01 -1.22649378e-01]\n",
            " [ 4.28506944e-01  1.52232020e-01  2.81790196e-01 -1.65313962e-01\n",
            "   2.46891867e-01 -8.26825025e-02  1.73054474e-01 -4.34918487e-02\n",
            "   1.69109841e-01  4.63735275e-01 -2.38308383e-01  1.77968821e-01\n",
            "   2.70704406e-01  1.43795554e-01 -2.31356769e-01 -1.00498460e-01\n",
            "   1.28107296e-01 -2.17412458e-02  2.74315140e-01 -7.07968253e-02]\n",
            " [ 7.96212361e-02  3.74493844e-01  1.54948775e-01 -1.30267962e-01\n",
            "  -3.05544170e-01 -2.17750351e-01 -2.78467644e-01  1.69030088e-01\n",
            "   1.66900265e-01  2.48227771e-02  4.19303978e-02 -2.41395067e-01\n",
            "  -1.53095573e-01  1.42945405e-01 -3.01130061e-01 -6.58119855e-02\n",
            "  -1.05408086e-02  2.70082922e-01 -3.76192368e-01 -3.51550465e-01]\n",
            " [-1.00141599e-01  1.45982727e-01 -1.23187184e-01  1.07382866e-01\n",
            "  -1.04004149e-01  1.48924371e-01  9.34914948e-02  5.01697287e-01\n",
            "   2.59462060e-01 -1.21419191e-01 -4.92496595e-01 -3.44803687e-01\n",
            "   2.25137808e-01  4.20529901e-02  2.81979031e-02  1.43937866e-01\n",
            "  -2.59366670e-01 -9.23370025e-02  2.27869791e-01  5.76382855e-02]\n",
            " [ 1.06144238e-01 -1.94063610e-01  2.49191102e-01  8.07839240e-02\n",
            "  -9.36589852e-02 -1.64249646e-01  1.44820435e-01  2.86550711e-01\n",
            "   1.42856939e-01 -1.41455586e-01  1.62800241e-01  1.76781107e-01\n",
            "  -1.34265900e-01  7.77610126e-02 -4.16529288e-02 -6.82426494e-02\n",
            "  -1.26732416e-01  5.86189665e-01  1.62020836e-01  4.78588204e-01]\n",
            " [ 3.48310677e-02  2.27291446e-01 -2.67023324e-01 -1.83376864e-02\n",
            "   1.43659383e-01  2.74889252e-01  7.66303822e-02 -9.87385079e-02\n",
            "   3.54934460e-01 -1.08336549e-01  9.43076862e-02 -1.22284952e-01\n",
            "   1.20674748e-01 -2.68103594e-01 -1.15114424e-01 -6.00482273e-01\n",
            "   1.51156352e-01  5.27160559e-02 -1.91373478e-01  2.82095652e-01]\n",
            " [ 3.72606383e-01  1.76239125e-01  8.03979524e-02  2.46921893e-01\n",
            "  -2.04120753e-01  2.96361936e-02  3.70594409e-01  1.65697815e-01\n",
            "  -4.80091522e-02  1.50994734e-01  4.22991919e-01 -5.08153481e-02\n",
            "  -5.75847818e-02 -2.29070506e-01  2.48194083e-01 -1.05114529e-01\n",
            "  -3.63458532e-01 -2.29399291e-01 -3.11646077e-03 -1.88539812e-01]\n",
            " [-1.04195500e-01 -1.22499845e-01 -2.67059981e-01 -3.00041457e-01\n",
            "   1.04731253e-01 -3.55699077e-01 -1.33827143e-01  1.36789701e-01\n",
            "  -7.35657678e-03  4.70897704e-01 -1.21428429e-01 -9.48625810e-02\n",
            "  -2.09596296e-01 -5.34717699e-01  8.81708702e-02 -3.60632582e-02\n",
            "  -1.85958510e-01  1.13829473e-01  5.35103117e-02  6.17064510e-02]\n",
            " [-3.07829868e-01 -1.99191017e-01 -3.13669728e-02 -4.26603431e-02\n",
            "  -4.57594255e-01  2.07975662e-01  1.96099393e-01 -2.33716995e-01\n",
            "  -9.71790181e-02  3.21098721e-01 -1.72336776e-01 -1.65021094e-02\n",
            "   2.58118308e-02  2.62255260e-01  1.02771377e-01 -4.30981304e-01\n",
            "  -1.57793949e-01  2.14200822e-01  1.03671434e-01 -1.65030000e-01]\n",
            " [-2.44788568e-01  4.00395732e-01  6.88599530e-02 -3.05773783e-01\n",
            "  -9.97149324e-02 -2.52574844e-01  2.28468616e-01  2.25510956e-01\n",
            "  -3.31246572e-01  3.27022820e-02 -2.22336477e-02  1.79706172e-01\n",
            "   2.13434230e-01  1.46307317e-01  2.39528429e-01 -7.96534635e-02\n",
            "   1.17657823e-01 -1.63944770e-01 -2.70967157e-01  3.41067335e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.4.4-3.4.5. Check Orthogonality of Eigenvectors\n",
        "# Check orthogonality (dot product of each pair should be zero)\n",
        "orthogonality_check = np.allclose(np.dot(eigenvectors.T, eigenvectors), np.eye(eigenvectors.shape[0]))\n",
        "print(f\"Are eigenvectors orthogonal? {orthogonality_check}\")\n",
        "\n",
        "# If not orthogonal, normalize them\n",
        "if not orthogonality_check:\n",
        "    eigenvectors = np.linalg.qr(eigenvectors)[0]  # Orthogonalize using QR decomposition\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xGrmLVCptD2",
        "outputId": "d25dbef0-2a7a-49e9-b3fd-b4d4eddcbf86"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Are eigenvectors orthogonal? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.4.6-3.4.7. Check Orthonormality and Apply Gram-Schmidt if Necessary\n",
        "# Check orthonormality (magnitude of each vector = 1)\n",
        "magnitudes = np.linalg.norm(eigenvectors, axis=0)\n",
        "orthonormality_check = np.allclose(magnitudes, 1)\n",
        "print(f\"Are eigenvectors orthonormal? {orthonormality_check}\")\n",
        "\n",
        "if not orthonormality_check:\n",
        "    # Gram-Schmidt process\n",
        "    def gram_schmidt(vectors):\n",
        "        ortho_vectors = []\n",
        "        for v in vectors.T:\n",
        "            for u in ortho_vectors:\n",
        "                v = v - np.dot(u, v) * u\n",
        "            v = v / np.linalg.norm(v)\n",
        "            ortho_vectors.append(v)\n",
        "        return np.array(ortho_vectors).T\n",
        "\n",
        "    eigenvectors = gram_schmidt(eigenvectors)\n",
        "    eigenvalues = np.diagonal(np.dot(eigenvectors.T, np.dot(np.cov(ratings_array, rowvar=False), eigenvectors)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgmecX1hp0bM",
        "outputId": "5a4ebcb4-caea-4a49-a975-28640cb48483"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Are eigenvectors orthonormal? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.4.8. Construct the Diagonal Matrix\n",
        "Z = np.diag(eigenvalues)\n",
        "print(\"Diagonal Matrix Z:\\n\", Z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_SQsU10qH-9",
        "outputId": "cd235b24-a648-446d-ae35-8251bdb7e84a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagonal Matrix Z:\n",
            " [[2.65665233 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         2.38657587 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         2.28675773 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.45522261 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         2.16178676 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.97710415\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.92360098 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.77681622 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.61524099 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.65715421 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.75495315 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.8432728\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.87047296 0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         1.08510144 0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         1.47743105 0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.44487314 0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         1.37470281 0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         1.32714144\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  1.22293507 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         1.23375071]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.4.9. Construct the Item Matrix\n",
        "U = eigenvectors\n",
        "print(\"Item Matrix U:\\n\", U)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LBIY46iqo89",
        "outputId": "c31910e4-c77d-4e04-d5ba-e3f22ba0bf2c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item Matrix U:\n",
            " [[-2.23863514e-02  3.46253098e-01 -3.95054667e-01  1.26582225e-01\n",
            "  -6.15926912e-02 -7.22450082e-02 -6.50679168e-02 -3.40535648e-01\n",
            "   3.84792846e-01  1.84981564e-01  7.30815944e-02  2.93268059e-01\n",
            "   1.05120916e-02  2.36289058e-01  1.59547505e-01  3.38052696e-01\n",
            "  -2.68304843e-01  1.11792397e-01 -3.32515342e-02  1.52988550e-01]\n",
            " [ 4.27450124e-01 -3.28965030e-01 -5.68857482e-02  9.00845845e-02\n",
            "   1.30888563e-01  8.44316069e-03 -7.18933735e-03 -1.18271588e-02\n",
            "  -2.28222473e-02  1.43777872e-01 -2.67857137e-01 -2.51310165e-01\n",
            "  -3.00698880e-02  2.65347364e-01  3.28274840e-01  1.42955144e-04\n",
            "  -1.88955003e-02  3.55594245e-02 -5.59348540e-01  1.75086315e-01]\n",
            " [-4.16719166e-01 -4.13109543e-02  5.06852037e-01  2.51840213e-01\n",
            "   1.39647726e-01  1.13568825e-01  1.81941436e-02 -2.07086125e-02\n",
            "   2.84518173e-01  2.47712791e-01  4.66601913e-02 -3.67729302e-03\n",
            "   2.74046139e-01 -2.74809562e-01  1.81897285e-01  1.78191947e-01\n",
            "   5.36795832e-02  1.32751776e-01 -2.92838342e-01 -7.02460559e-02]\n",
            " [ 6.10394705e-02  1.18759326e-01  1.92295960e-01  1.00333932e-01\n",
            "  -2.17673083e-01 -4.50734614e-02 -3.37572677e-01  4.09887855e-02\n",
            "   2.59215843e-01  3.14554109e-02 -1.06301875e-01  3.60090152e-02\n",
            "  -3.37012504e-01  1.36559499e-02  5.08346158e-01 -1.80842680e-01\n",
            "   4.04639536e-01 -1.98614518e-01  2.76158289e-01  7.04987326e-02]\n",
            " [ 2.64623311e-01  2.59613774e-03 -1.53772039e-03 -6.69121674e-02\n",
            "  -4.07163706e-01 -3.79780245e-02  1.79255339e-01 -2.12573407e-01\n",
            "  -3.46786931e-03 -2.97720515e-01 -4.14619120e-01  2.94411748e-01\n",
            "   1.26290178e-01 -4.68866878e-01  6.10835317e-02  1.47399318e-01\n",
            "   1.18385638e-01  1.67630416e-01 -1.34877202e-01 -1.10257442e-01]\n",
            " [ 1.25860103e-01 -6.49992572e-02 -2.68018895e-01  1.16136916e-01\n",
            "  -1.91559608e-02  2.18764306e-01 -4.32232869e-01  4.23076592e-01\n",
            "  -1.75489495e-01  1.16119269e-01  1.23637336e-01  3.82998076e-01\n",
            "   4.01753196e-01 -5.69807762e-03  1.27565633e-01 -1.00131111e-01\n",
            "   8.69395618e-02  2.03989183e-01 -1.81772693e-02 -1.92553395e-01]\n",
            " [-1.66930826e-01 -6.30064752e-04 -1.98344496e-01  4.21797471e-01\n",
            "   1.27503644e-01 -6.47651762e-02  3.26095324e-01  2.73839914e-01\n",
            "   3.63892477e-02  1.16439954e-01 -2.25874969e-01  3.54614024e-01\n",
            "  -4.27378660e-01  4.59141694e-02 -2.28299255e-01 -7.28212186e-02\n",
            "   2.20232973e-01 -7.37791172e-02 -1.95745281e-01 -1.64324671e-01]\n",
            " [ 7.76662851e-02  5.47872516e-02  1.33254481e-01 -6.10665309e-02\n",
            "  -2.91292238e-01  5.39181383e-01 -1.68803615e-01  5.47158546e-02\n",
            "  -1.41537547e-01  3.15624405e-01 -2.83274934e-02  7.59050023e-02\n",
            "  -2.29409260e-01 -1.18771114e-01 -3.28017416e-01  2.29805934e-01\n",
            "  -2.15909784e-02 -1.71617484e-01 -1.07391127e-01  4.09408828e-01]\n",
            " [-1.02510010e-02  2.71790181e-01  2.70752787e-01  6.26273061e-02\n",
            "   3.44104604e-01  1.28789884e-01 -2.48691400e-01 -1.04132508e-01\n",
            "  -2.21001124e-01 -1.85925388e-01 -3.16307093e-01  2.35452120e-01\n",
            "  -2.04649786e-01 -4.26388207e-02  9.94571791e-02 -2.63011328e-01\n",
            "  -5.23238546e-01  5.79105641e-02 -3.13421227e-02 -3.64897632e-02]\n",
            " [ 1.87078954e-02  1.76930305e-01 -5.78983867e-02 -4.15332982e-01\n",
            "   2.41548846e-01  4.49731532e-01  2.77119910e-01  1.17615554e-01\n",
            "  -1.51916998e-03 -1.91914834e-02  6.63053685e-02 -5.18344513e-02\n",
            "  -2.83470754e-01  4.31408501e-02  2.97268671e-01  2.28095809e-01\n",
            "   1.72023932e-01  3.56218186e-01  4.86111952e-02 -2.28790607e-01]\n",
            " [-4.84407488e-02 -3.51509594e-01  7.56834862e-02 -4.66192829e-01\n",
            "  -4.08760633e-02  5.74730952e-02 -3.74415986e-03  1.71104620e-01\n",
            "   4.58882006e-01 -1.47140488e-01  7.48966992e-02  3.56842986e-01\n",
            "  -4.43901756e-02  9.43593499e-02  5.57103824e-04 -7.32822536e-02\n",
            "  -2.42898456e-01 -3.57257298e-01 -1.83511324e-01 -1.22649378e-01]\n",
            " [ 4.28506944e-01  1.52232020e-01  2.81790196e-01 -1.65313962e-01\n",
            "   2.46891867e-01 -8.26825025e-02  1.73054474e-01 -4.34918487e-02\n",
            "   1.69109841e-01  4.63735275e-01 -2.38308383e-01  1.77968821e-01\n",
            "   2.70704406e-01  1.43795554e-01 -2.31356769e-01 -1.00498460e-01\n",
            "   1.28107296e-01 -2.17412458e-02  2.74315140e-01 -7.07968253e-02]\n",
            " [ 7.96212361e-02  3.74493844e-01  1.54948775e-01 -1.30267962e-01\n",
            "  -3.05544170e-01 -2.17750351e-01 -2.78467644e-01  1.69030088e-01\n",
            "   1.66900265e-01  2.48227771e-02  4.19303978e-02 -2.41395067e-01\n",
            "  -1.53095573e-01  1.42945405e-01 -3.01130061e-01 -6.58119855e-02\n",
            "  -1.05408086e-02  2.70082922e-01 -3.76192368e-01 -3.51550465e-01]\n",
            " [-1.00141599e-01  1.45982727e-01 -1.23187184e-01  1.07382866e-01\n",
            "  -1.04004149e-01  1.48924371e-01  9.34914948e-02  5.01697287e-01\n",
            "   2.59462060e-01 -1.21419191e-01 -4.92496595e-01 -3.44803687e-01\n",
            "   2.25137808e-01  4.20529901e-02  2.81979031e-02  1.43937866e-01\n",
            "  -2.59366670e-01 -9.23370025e-02  2.27869791e-01  5.76382855e-02]\n",
            " [ 1.06144238e-01 -1.94063610e-01  2.49191102e-01  8.07839240e-02\n",
            "  -9.36589852e-02 -1.64249646e-01  1.44820435e-01  2.86550711e-01\n",
            "   1.42856939e-01 -1.41455586e-01  1.62800241e-01  1.76781107e-01\n",
            "  -1.34265900e-01  7.77610126e-02 -4.16529288e-02 -6.82426494e-02\n",
            "  -1.26732416e-01  5.86189665e-01  1.62020836e-01  4.78588204e-01]\n",
            " [ 3.48310677e-02  2.27291446e-01 -2.67023324e-01 -1.83376864e-02\n",
            "   1.43659383e-01  2.74889252e-01  7.66303822e-02 -9.87385079e-02\n",
            "   3.54934460e-01 -1.08336549e-01  9.43076862e-02 -1.22284952e-01\n",
            "   1.20674748e-01 -2.68103594e-01 -1.15114424e-01 -6.00482273e-01\n",
            "   1.51156352e-01  5.27160559e-02 -1.91373478e-01  2.82095652e-01]\n",
            " [ 3.72606383e-01  1.76239125e-01  8.03979524e-02  2.46921893e-01\n",
            "  -2.04120753e-01  2.96361936e-02  3.70594409e-01  1.65697815e-01\n",
            "  -4.80091522e-02  1.50994734e-01  4.22991919e-01 -5.08153481e-02\n",
            "  -5.75847818e-02 -2.29070506e-01  2.48194083e-01 -1.05114529e-01\n",
            "  -3.63458532e-01 -2.29399291e-01 -3.11646077e-03 -1.88539812e-01]\n",
            " [-1.04195500e-01 -1.22499845e-01 -2.67059981e-01 -3.00041457e-01\n",
            "   1.04731253e-01 -3.55699077e-01 -1.33827143e-01  1.36789701e-01\n",
            "  -7.35657678e-03  4.70897704e-01 -1.21428429e-01 -9.48625810e-02\n",
            "  -2.09596296e-01 -5.34717699e-01  8.81708702e-02 -3.60632582e-02\n",
            "  -1.85958510e-01  1.13829473e-01  5.35103117e-02  6.17064510e-02]\n",
            " [-3.07829868e-01 -1.99191017e-01 -3.13669728e-02 -4.26603431e-02\n",
            "  -4.57594255e-01  2.07975662e-01  1.96099393e-01 -2.33716995e-01\n",
            "  -9.71790181e-02  3.21098721e-01 -1.72336776e-01 -1.65021094e-02\n",
            "   2.58118308e-02  2.62255260e-01  1.02771377e-01 -4.30981304e-01\n",
            "  -1.57793949e-01  2.14200822e-01  1.03671434e-01 -1.65030000e-01]\n",
            " [-2.44788568e-01  4.00395732e-01  6.88599530e-02 -3.05773783e-01\n",
            "  -9.97149324e-02 -2.52574844e-01  2.28468616e-01  2.25510956e-01\n",
            "  -3.31246572e-01  3.27022820e-02 -2.22336477e-02  1.79706172e-01\n",
            "   2.13434230e-01  1.46307317e-01  2.39528429e-01 -7.96534635e-02\n",
            "   1.17657823e-01 -1.63944770e-01 -2.70967157e-01  3.41067335e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.4.10. Construct the User Matrix\n",
        "# Transpose of predicted user matrix\n",
        "V_T = np.dot(U, Z)\n",
        "print(\"User Matrix V^T:\\n\", V_T)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM0wnGjBqwes",
        "outputId": "c51fca16-e91a-485a-c82f-307bdf418e77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Matrix V^T:\n",
            " [[-5.94727524e-02  8.26359289e-01 -9.03394313e-01  5.76230915e-02\n",
            "  -1.33150264e-01 -1.42835905e-01 -1.25164709e-01 -6.05069264e-01\n",
            "   2.36740331e-01  1.21561414e-01  5.51731797e-02  2.47304978e-01\n",
            "   9.15049150e-03  2.56397596e-01  2.35720439e-01  4.88443262e-01\n",
            "  -3.68839422e-01  1.48364323e-01 -4.06644672e-02  1.88749732e-01]\n",
            " [ 1.13558637e+00 -7.85100004e-01 -1.30083924e-01  4.10085401e-02\n",
            "   2.82953162e-01  1.66930080e-02 -1.38294164e-02 -2.10146877e-02\n",
            "  -1.40411820e-02  9.44842341e-02 -2.02219589e-01 -2.11923027e-01\n",
            "  -2.61750243e-02  2.87928806e-01  4.85003444e-01  2.06552049e-04\n",
            "  -2.59756973e-02  4.71923858e-02 -6.84046944e-01  2.16012865e-01]\n",
            " [-1.10707794e+00 -9.85917268e-02  1.15904781e+00  1.14643360e-01\n",
            "   3.01888606e-01  2.24537395e-01  3.49982726e-02 -3.67953986e-02\n",
            "   1.75047242e-01  1.62785504e-01  3.52262583e-02 -3.10096119e-03\n",
            "   2.38549753e-01 -2.98196250e-01  2.68740698e-01  2.57464759e-01\n",
            "   7.37934739e-02  1.76180383e-01 -3.58122277e-01 -8.66661211e-02]\n",
            " [ 1.62160651e-01  2.83428141e-01  4.39734274e-01  4.56742747e-02\n",
            "  -4.70562788e-01 -8.91149277e-02 -6.49355135e-01  7.28295391e-02\n",
            "   1.59480212e-01  2.06710558e-02 -8.02529350e-02  3.03654232e-02\n",
            "  -2.93360271e-01  1.48180908e-02  7.51046400e-01 -2.61294731e-01\n",
            "   5.56259107e-01 -2.63589557e-01  3.37723656e-01  8.69778612e-02]\n",
            " [ 7.03012135e-01  6.19587970e-03 -3.51639400e-03 -3.04599318e-02\n",
            "  -8.80201108e-01 -7.50865098e-02  3.44815747e-01 -3.77703879e-01\n",
            "  -2.13357535e-03 -1.95648290e-01 -3.13018010e-01  2.48269420e-01\n",
            "   1.09932185e-01 -5.08768122e-01  9.02467067e-02  2.12973316e-01\n",
            "   1.62745069e-01  2.22469271e-01 -1.64946060e-01 -1.36030197e-01]\n",
            " [ 3.34366536e-01 -1.55125659e-01 -6.12894280e-01  5.28681508e-02\n",
            "  -4.14111025e-02  4.32519817e-01 -8.31443573e-01  7.51729351e-01\n",
            "  -1.07968330e-01  7.63082668e-02  9.33403963e-02  3.22971861e-01\n",
            "   3.49715293e-01 -6.18299221e-03  1.88469428e-01 -1.44676754e-01\n",
            "   1.19516060e-01  2.70722497e-01 -2.22296201e-02 -2.37562888e-01]\n",
            " [-4.43477167e-01 -1.50369733e-03 -4.53565808e-01  1.92011747e-01\n",
            "   2.75635690e-01 -1.28047499e-01  6.27277286e-01  4.86563202e-01\n",
            "   2.23881568e-02  7.65190061e-02 -1.70525019e-01  2.99036362e-01\n",
            "  -3.72021566e-01  4.98215311e-02 -3.37296410e-01 -1.05217423e-01\n",
            "   3.02754887e-01 -9.79153236e-02 -2.39383768e-01 -2.02735679e-01]\n",
            " [ 2.06332317e-01  1.30753933e-01  3.04720715e-01 -2.77988659e-02\n",
            "  -6.29711702e-01  1.06601775e+00 -3.24710800e-01  9.72200181e-02\n",
            "  -8.70797003e-02  2.07413908e-01 -2.13859303e-02  6.40086241e-02\n",
            "  -1.99694557e-01 -1.28878706e-01 -4.84623117e-01  3.32040422e-01\n",
            "  -2.96811787e-02 -2.27760674e-01 -1.31332375e-01  5.05108431e-01]\n",
            " [-2.72333455e-02  6.48647890e-01  6.19146027e-01  2.85093661e-02\n",
            "   7.43880777e-01  2.54631013e-01 -4.78383022e-01 -1.85024330e-01\n",
            "  -1.35968950e-01 -1.22181652e-01 -2.38797035e-01  1.98550369e-01\n",
            "  -1.78142105e-01 -4.62674456e-02  1.46941125e-01 -3.80018004e-01\n",
            "  -7.19297500e-01  7.68555093e-02 -3.83293809e-02 -4.50192711e-02]\n",
            " [ 4.97003737e-02  4.22257597e-01 -1.32399583e-01 -1.89068966e-01\n",
            "   5.22177097e-01  8.89166077e-01  5.33068131e-01  2.08981224e-01\n",
            "  -9.34655641e-04 -1.26117641e-02  5.00574466e-02 -4.37105830e-02\n",
            "  -2.46753625e-01  4.68121984e-02  4.39193966e-01  3.29569509e-01\n",
            "   2.36481783e-01  4.72751915e-01  5.94483353e-02 -2.82270573e-01]\n",
            " [-1.28690228e-01 -8.38904315e-01  1.73069797e-01 -2.12221518e-01\n",
            "  -8.83653323e-02  1.13630295e-01 -7.20226959e-03  3.04021464e-01\n",
            "   2.82323019e-01 -9.66939915e-02  5.65434988e-02  3.00915985e-01\n",
            "  -3.86404475e-02  1.02389466e-01  8.23082490e-04 -1.05883560e-01\n",
            "  -3.33913190e-01 -4.74130963e-01 -2.24422433e-01 -1.51318756e-01]\n",
            " [ 1.13839397e+00  3.63313267e-01  6.44385908e-01 -7.52546540e-02\n",
            "   5.33727568e-01 -1.63471919e-01  3.32887756e-01 -7.72770223e-02\n",
            "   1.04043306e-01  3.04745589e-01 -1.79911664e-01  1.50076266e-01\n",
            "   2.35640865e-01  1.56032762e-01 -3.41813676e-01 -1.45207526e-01\n",
            "   1.76109459e-01 -2.88537082e-02  3.35469604e-01 -8.73456333e-02]\n",
            " [ 2.11525942e-01  8.93757974e-01  3.54330308e-01 -5.93009221e-02\n",
            "  -6.60521342e-01 -4.30515123e-01 -5.35660635e-01  3.00335402e-01\n",
            "   1.02683884e-01  1.63123925e-02  3.16554858e-02 -2.03561895e-01\n",
            "  -1.33265556e-01  1.55110264e-01 -4.44898903e-01 -9.50899705e-02\n",
            "  -1.44904792e-02  3.58438237e-01 -4.60058838e-01 -4.33725635e-01]\n",
            " [-2.66041412e-01  3.48398854e-01 -2.81699244e-01  4.88831089e-02\n",
            "  -2.24834793e-01  2.94438992e-01  1.79840331e-01  8.91423879e-01\n",
            "   1.59631695e-01 -7.97911326e-02 -3.71811855e-01 -2.90763572e-01\n",
            "   1.95976373e-01  4.56317600e-02  4.16604577e-02  2.07971957e-01\n",
            "  -3.56552091e-01 -1.22544262e-01  2.78669959e-01  7.11112754e-02]\n",
            " [ 2.81988335e-01 -4.63147529e-01  5.69839678e-01  3.67746691e-02\n",
            "  -2.02470754e-01 -3.24738657e-01  2.78576731e-01  5.09147952e-01\n",
            "   8.78914443e-02 -9.29581342e-02  1.22906555e-01  1.49074700e-01\n",
            "  -1.16874835e-01  8.43785864e-02 -6.15393306e-02 -9.86019714e-02\n",
            "  -1.74219408e-01  7.77956595e-01  1.98140962e-01  5.90458535e-01]\n",
            " [ 9.25340369e-02  5.42448282e-01 -6.10617650e-01 -8.34772955e-03\n",
            "   3.10560952e-01  5.43484681e-01  1.47406279e-01 -1.75440182e-01\n",
            "   2.18370228e-01 -7.11938197e-02  7.11978846e-02 -1.03119574e-01\n",
            "   1.05044105e-01 -2.90919594e-01 -1.70073625e-01 -8.67620711e-01\n",
            "   2.07795062e-01  6.99616621e-02 -2.34037337e-01  3.48035710e-01]\n",
            " [ 9.89885613e-01  4.20608043e-01  1.83850639e-01  1.12404430e-01\n",
            "  -4.41265540e-01  5.85938414e-02  7.12875771e-01  2.94414565e-01\n",
            "  -2.95371983e-02  9.92268252e-02  3.19339081e-01 -4.28512010e-02\n",
            "  -5.01259953e-02 -2.48564735e-01  3.66689646e-01 -1.51877160e-01\n",
            "  -4.99647465e-01 -3.04445305e-01 -3.81122916e-03 -2.32611126e-01]\n",
            " [-2.76811218e-01 -2.92355174e-01 -6.10701475e-01 -1.36585657e-01\n",
            "   2.26406636e-01 -7.03254122e-01 -2.57430025e-01  2.43050159e-01\n",
            "  -4.52606758e-03  3.09452410e-01 -9.16727748e-02 -7.99950345e-02\n",
            "  -1.82447908e-01 -5.80222942e-01  1.30266382e-01 -5.21068333e-02\n",
            "  -2.55637686e-01  1.51067810e-01  6.54396367e-02  7.61303775e-02]\n",
            " [-8.17796934e-01 -4.75384476e-01 -7.17286675e-02 -1.94199529e-02\n",
            "  -9.89221202e-01  4.11189544e-01  3.77216985e-01 -4.15272147e-01\n",
            "  -5.97885153e-02  2.11011377e-01 -1.30106191e-01 -1.39157800e-02\n",
            "   2.24685007e-02  2.84573559e-01  1.51837623e-01 -6.22713312e-01\n",
            "  -2.16919785e-01  2.84274786e-01  1.26783432e-01 -2.03605879e-01]\n",
            " [-6.50318118e-01  9.55574795e-01  1.57466030e-01 -1.39195141e-01\n",
            "  -2.15562421e-01 -4.99366772e-01  4.39482455e-01  4.00691525e-01\n",
            "  -2.03796469e-01  2.14904424e-02 -1.67853623e-02  1.51541327e-01\n",
            "   1.85788725e-01  1.58758280e-01  3.53886740e-01 -1.15089150e-01\n",
            "   1.61744540e-01 -2.17577897e-01 -3.31375238e-01  4.20792065e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.4.11. Construct the Reduced Rating Matrix\n",
        "# Reconstruct the rating matrix\n",
        "R = np.dot(U, np.dot(Z, V_T.T))\n",
        "print(\"Reduced Rating Matrix R:\\n\", R)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKC8tCofq5JV",
        "outputId": "401c7536-9b07-4841-ac96-a1fcdfeb7fbf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced Rating Matrix R:\n",
            " [[ 2.61608045e+00 -4.04267404e-01 -9.36125575e-01 -2.05178108e-01\n",
            "   2.47742305e-01 -2.13004641e-03 -1.42494023e-01 -1.57548600e-01\n",
            "   1.10537877e-01  2.56657681e-01 -9.01302830e-01 -5.16406977e-01\n",
            "   2.97528010e-01  1.63010467e-01 -8.87637689e-01  4.55535517e-01\n",
            "  -3.23686730e-02  2.69102604e-01 -1.19208892e-01  5.42111958e-01]\n",
            " [-4.04267404e-01  2.93674466e+00 -9.58997088e-01 -7.43468152e-02\n",
            "   5.21928678e-01  5.50001512e-01 -4.32627231e-01 -1.33368898e-01\n",
            "  -2.96400959e-01  3.07312612e-02  5.01563810e-01  7.16484913e-01\n",
            "  -5.95501873e-01 -6.33414199e-01  4.98229025e-01 -8.14511493e-02\n",
            "   6.47473074e-01 -9.07291797e-03 -7.23208740e-01 -1.10699922e+00]\n",
            " [-9.36125575e-01 -9.58997088e-01  3.25098478e+00  7.46156340e-02\n",
            "  -7.08015549e-01 -8.51790052e-01 -5.75762237e-02  6.75521182e-02\n",
            "   7.97215207e-01  3.30126821e-01  3.42104578e-01 -5.82149933e-01\n",
            "  -1.79559413e-01 -1.42207540e-01  1.66369347e-01 -6.83717188e-01\n",
            "  -9.42325503e-01 -3.20317505e-01  5.15686681e-01  7.00750489e-01]\n",
            " [-2.05178108e-01 -7.43468152e-02  7.46156340e-02  2.21079234e+00\n",
            "   2.47251718e-01  3.49046374e-01 -7.45501328e-01  2.65600562e-01\n",
            "   2.02401222e-01 -2.81476855e-01 -1.94908892e-01  7.66855227e-02\n",
            "   6.04062642e-01 -1.39119195e-01 -1.47419960e-02 -2.66475519e-01\n",
            "   2.03980943e-01 -2.47856941e-01 -3.73917162e-02  4.07612932e-01]\n",
            " [ 2.47742305e-01  5.21928678e-01 -7.08015549e-01  2.47251718e-01\n",
            "   2.18117764e+00 -1.52289603e-01 -4.28455257e-01  4.21423452e-01\n",
            "  -7.90123888e-01 -1.70645397e-01 -2.43591687e-01  3.86308136e-01\n",
            "   4.64821475e-01 -3.19342536e-01  2.64519516e-01 -1.60609886e-01\n",
            "   1.08802533e+00 -3.22194925e-01  3.19343980e-01 -2.58619032e-01]\n",
            " [-2.13004641e-03  5.50001512e-01 -8.51790052e-01  3.49046374e-01\n",
            "  -1.52289603e-01  2.41328260e+00 -1.14002624e-01  3.43897420e-01\n",
            "  -1.35463122e-01  2.59293349e-01  1.95752549e-01 -3.94056175e-01\n",
            "   2.42350426e-01  4.84681114e-01 -1.12703165e-01  3.30992621e-01\n",
            "  -1.53753739e-01  3.55455470e-01 -3.36448140e-01 -6.54611421e-01]\n",
            " [-1.42494023e-01 -4.32627231e-01 -5.75762237e-02 -7.45501328e-01\n",
            "  -4.28455257e-01 -1.14002624e-01  1.75209045e+00 -5.26246126e-01\n",
            "  -5.46819939e-01  4.24235355e-01  1.82921783e-01 -3.27427548e-01\n",
            "  -2.70833233e-01  3.91763514e-01 -1.66274404e-01  3.49682863e-01\n",
            "  -2.75305530e-01  3.75714183e-01  7.18188420e-02  6.05067879e-01]\n",
            " [-1.57548600e-01 -1.33368898e-01  6.75521182e-02  2.65600562e-01\n",
            "   4.21423452e-01  3.43897420e-01 -5.26246126e-01  2.58301114e+00\n",
            "   4.20245472e-02  1.64995788e-01  1.34383235e-01 -1.14081476e-01\n",
            "   3.61787671e-01  3.87742490e-01  3.41949284e-04  1.76441985e-01\n",
            "   2.44283956e-01 -9.67431153e-01  1.97737093e-01 -3.91918772e-01]\n",
            " [ 1.10537877e-01 -2.96400959e-01  7.97215207e-01  2.02401222e-01\n",
            "  -7.90123888e-01 -1.35463122e-01 -5.46819939e-01  4.20245472e-02\n",
            "   2.54345460e+00  3.45129646e-01 -2.47815070e-01  6.51257074e-01\n",
            "   3.89900088e-01 -1.40698360e-01 -2.19080728e-01  3.92602268e-01\n",
            "   3.98428136e-02 -2.39916639e-01 -6.31207102e-01  1.34350998e-01]\n",
            " [ 2.56657681e-01  3.07312612e-02  3.30126821e-01 -2.81476855e-01\n",
            "  -1.70645397e-01  2.59293349e-01  4.24235355e-01  1.64995788e-01\n",
            "   3.45129646e-01  2.35695956e+00 -5.32143563e-01  2.37829624e-01\n",
            "  -5.13586199e-01  4.78319691e-01 -2.57838940e-01  5.82056372e-01\n",
            "   3.76137378e-01 -5.77774632e-01 -2.56016353e-01  6.52648107e-03]\n",
            " [-9.01302830e-01  5.01563810e-01  3.42104578e-01 -1.94908892e-01\n",
            "  -2.43591687e-01  1.95752549e-01  1.82921783e-01  1.34383235e-01\n",
            "  -2.47815070e-01 -5.32143563e-01  1.52406724e+00 -4.65756499e-01\n",
            "  -5.96024713e-01  2.91138393e-02  2.41503915e-01 -5.94250540e-01\n",
            "  -1.49120834e-02  6.03415604e-02  4.86426927e-01 -5.13757505e-01]\n",
            " [-5.16406977e-01  7.16484913e-01 -5.82149933e-01  7.66855227e-02\n",
            "   3.86308136e-01 -3.94056175e-01 -3.27427548e-01 -1.14081476e-01\n",
            "   6.51257074e-01  2.37829624e-01 -4.65756499e-01  2.80560482e+00\n",
            "   3.23360487e-01 -4.86208913e-01  4.79408079e-01  1.10992624e-01\n",
            "   1.10839716e+00 -7.79502414e-01 -1.40444352e+00 -3.37036838e-01]\n",
            " [ 2.97528010e-01 -5.95501873e-01 -1.79559413e-01  6.04062642e-01\n",
            "   4.64821475e-01  2.42350426e-01 -2.70833233e-01  3.61787671e-01\n",
            "   3.89900088e-01 -5.13586199e-01 -5.96024713e-01  3.23360487e-01\n",
            "   2.80188412e+00  1.52890236e-01  1.03262498e-01 -1.59899811e-01\n",
            "   4.54192576e-01 -2.70023973e-01 -3.08686963e-01  7.13861921e-01]\n",
            " [ 1.63010467e-01 -6.33414199e-01 -1.42207540e-01 -1.39119195e-01\n",
            "  -3.19342536e-01  4.84681114e-01  3.91763514e-01  3.87742490e-01\n",
            "  -1.40698360e-01  4.78319691e-01  2.91138393e-02 -4.86208913e-01\n",
            "   1.52890236e-01  1.80310148e+00  1.30340262e-02  3.69915771e-02\n",
            "   3.85481387e-01  1.10113518e-01  9.59448189e-02  6.61390778e-01]\n",
            " [-8.87637689e-01  4.98229025e-01  1.66369347e-01 -1.47419960e-02\n",
            "   2.64519516e-01 -1.12703165e-01 -1.66274404e-01  3.41949284e-04\n",
            "  -2.19080728e-01 -2.57838940e-01  2.41503915e-01  4.79408079e-01\n",
            "   1.03262498e-01  1.30340262e-02  2.21483323e+00 -6.05298763e-01\n",
            "   3.22474476e-01  7.59982856e-02  1.02736493e-01 -4.18668906e-02]\n",
            " [ 4.55535517e-01 -8.14511493e-02 -6.83717188e-01 -2.66475519e-01\n",
            "  -1.60609886e-01  3.30992621e-01  3.49682863e-01  1.76441985e-01\n",
            "   3.92602268e-01  5.82056372e-01 -5.94250540e-01  1.10992624e-01\n",
            "  -1.59899811e-01  3.69915771e-02 -6.05298763e-01  2.28985972e+00\n",
            "   9.96970270e-02 -8.26196849e-02  2.75364912e-02  2.11859857e-01]\n",
            " [-3.23686730e-02  6.47473074e-01 -9.42325503e-01  2.03980943e-01\n",
            "   1.08802533e+00 -1.53753739e-01 -2.75305530e-01  2.44283956e-01\n",
            "   3.98428136e-02  3.76137378e-01 -1.49120834e-02  1.10839716e+00\n",
            "   4.54192576e-01  3.85481387e-01  3.22474476e-01  9.96970270e-02\n",
            "   2.72905487e+00 -4.99857971e-01 -2.88737735e-01  2.52189109e-01]\n",
            " [ 2.69102604e-01 -9.07291797e-03 -3.20317505e-01 -2.47856941e-01\n",
            "  -3.22194925e-01  3.55455470e-01  3.75714183e-01 -9.67431153e-01\n",
            "  -2.39916639e-01 -5.77774632e-01  6.03415604e-02 -7.79502414e-01\n",
            "  -2.70023973e-01  1.10113518e-01  7.59982856e-02 -8.26196849e-02\n",
            "  -4.99857971e-01  1.82334288e+00 -2.46547956e-01 -3.06690683e-02]\n",
            " [-1.19208892e-01 -7.23208740e-01  5.15686681e-01 -3.73917162e-02\n",
            "   3.19343980e-01 -3.36448140e-01  7.18188420e-02  1.97737093e-01\n",
            "  -6.31207102e-01 -2.56016353e-01  4.86426927e-01 -1.40444352e+00\n",
            "  -3.08686963e-01  9.59448189e-02  1.02736493e-01  2.75364912e-02\n",
            "  -2.88737735e-01 -2.46547956e-01  3.10561435e+00  4.31818336e-02]\n",
            " [ 5.42111958e-01 -1.10699922e+00  7.00750489e-01  4.07612932e-01\n",
            "  -2.58619032e-01 -6.54611421e-01  6.05067879e-01 -3.91918772e-01\n",
            "   1.34350998e-01  6.52648107e-03 -5.13757505e-01 -3.37036838e-01\n",
            "   7.13861921e-01  6.61390778e-01 -4.18668906e-02  2.11859857e-01\n",
            "   2.52189109e-01 -3.06690683e-02  4.31818336e-02  2.65356183e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.4.12. Predict Missing Ratings\n",
        "# Ensure original_dimensions reflects the reduced size of PCA\n",
        "original_dimensions = U.shape[0]  # Assuming this is 20 (reduced users)\n",
        "\n",
        "# Reconstruct the rating matrix using all components\n",
        "R_expanded = np.dot(U, np.dot(Z, V_T.T))  # Reconstruct the full matrix in original size\n",
        "\n",
        "# Align reconstructed matrix with original dataset dimensions\n",
        "predicted_ratings = pd.DataFrame(\n",
        "    R_expanded,\n",
        "    index=ratings_df.index[:original_dimensions],  # Adjust to match original indices\n",
        "    columns=ratings_df.columns\n",
        ")\n",
        "\n",
        "# Expand predictions for missing rows (if reduced)\n",
        "expanded_predictions = pd.DataFrame(index=ratings_df.index, columns=ratings_df.columns)\n",
        "expanded_predictions.update(predicted_ratings)\n",
        "\n",
        "# Find missing ratings in the original dataset\n",
        "missing_predictions = expanded_predictions[ratings_df.isna()]\n",
        "\n",
        "print(\"Predicted Missing Ratings for Target Items (11 and 12):\")\n",
        "print(missing_predictions[[target_items[0], target_items[1]]])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZdvmFGCrA2C",
        "outputId": "d295d047-e1dc-46fa-c444-974d172956a2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Missing Ratings for Target Items (11 and 12):\n",
            "           Item_11   Item_12\n",
            "User_1   -0.901303       NaN\n",
            "User_2         NaN       NaN\n",
            "User_3    0.342105  -0.58215\n",
            "User_4   -0.194909  0.076686\n",
            "User_5         NaN       NaN\n",
            "...            ...       ...\n",
            "User_96        NaN       NaN\n",
            "User_97        NaN       NaN\n",
            "User_98        NaN       NaN\n",
            "User_99        NaN       NaN\n",
            "User_100       NaN       NaN\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}